{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b598b15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.applications import resnet50\n",
    "from keras_applications import resnext\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddcdfd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_train_images: 2520\n",
      "Types: Index(['distribute', 'ineq', 'integral', 'limit', 'matrix', 'series', 'sqrt'], dtype='object')\n",
      "num_classes: 7\n"
     ]
    }
   ],
   "source": [
    "labels = pd.read_csv('Data/train_label.csv')\n",
    "labels['Type'].value_counts()\n",
    "sample = pd.read_csv('Data/sample_submission.csv')\n",
    "num_train_images = 2520  # we choose 3300 images for this assignment. It works for a machine having 8Gb Ram. You can adjust it if your Ram is different. \n",
    "split_point = 2240 # split the data into training data [0:3000] and val data [3000:]\n",
    "print('num_train_images:', num_train_images)\n",
    "types = sample.columns[1:]\n",
    "print('Types:', types)\n",
    "num_classes = len(types)\n",
    "print('num_classes:', num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb5b3caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "\n",
    "img_width = 224\n",
    "\n",
    "def get_image(filename):\n",
    "    ########################################################################\n",
    "    # TODO: Your code here...\n",
    "    ########################################################################\n",
    "    original = load_img(filename, target_size=(224,224))\n",
    "    numpy_image = img_to_array(original)\n",
    "    image_batch = np.expand_dims(numpy_image, axis=0)\n",
    "    return image_batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "561cb5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 images loaded\n",
      "2000 images loaded\n"
     ]
    }
   ],
   "source": [
    "x_train = np.zeros((num_train_images, img_width, img_width, 3), dtype=np.uint8)\n",
    "y_train = np.zeros((num_train_images, num_classes), dtype=np.uint8)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for i in range(num_train_images):\n",
    "    x_train[i] = get_image('Data/train/%s.png' % labels['id'][i])\n",
    "    pos_arrays = (types == labels['Type'][i]).nonzero() # recall that types is the array of classes\n",
    "    pos = pos_arrays[0][0]\n",
    "    y_train[i][pos] = 1\n",
    "    count += 1\n",
    "    if(count % 1000 == 0): print(count, 'images loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eedbf45",
   "metadata": {},
   "source": [
    "# concatenating with nothing changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc9d949f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 203s 5s/step\n",
      "(2520, 7, 7, 2048)\n",
      "40/40 [==============================] - 494s 12s/step\n",
      "(2520, 7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import inception_v3\n",
    "from tensorflow.keras.applications import vgg16\n",
    "\n",
    "#getting the features of all three models\n",
    "\n",
    "#Resnet50 - last layer of features\n",
    "resnet50_x_train = resnet50.preprocess_input(x_train.copy())\n",
    "resnet50_model = resnet50.ResNet50(weights='imagenet', include_top=False)\n",
    "resnet50_features = resnet50_model.predict(resnet50_x_train, batch_size=64, verbose=1)\n",
    "print(resnet50_features.shape)\n",
    "\n",
    "#vgg16\n",
    "vgg16_x_train = vgg16.preprocess_input(x_train.copy())\n",
    "vgg16_model = vgg16.VGG16(weights='imagenet', include_top=False)\n",
    "vgg16_features = vgg16_model.predict(vgg16_x_train, batch_size=64, verbose=1)\n",
    "print(vgg16_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58f00070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2520, 7, 7, 2560)\n"
     ]
    }
   ],
   "source": [
    "concat = np.concatenate([resnet50_features, vgg16_features],axis=3)\n",
    "print(concat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "835c4687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2560)\n",
      "(None, 7)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout, Activation, BatchNormalization\n",
    "\n",
    "inputs = Input(shape = (7, 7, 2560)) # to take 7 x 7 x 2048 images\n",
    "x = GlobalAveragePooling2D()(inputs) # to convert to 2048 feagures\n",
    "print(x.shape)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "x = Dense(500)(x) # add a dense layer, but not adding activation so that we can add batch-norm first\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "# Softmax layer to the output classes\n",
    "predictions = Dense(num_classes, activation='softmax')(x) # arg1 is: units = dimensionality of the output space.\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40d40014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 7, 7, 2560)]      0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2560)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2560)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 500)               1280500   \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 500)              2000      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 500)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 3507      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,286,007\n",
      "Trainable params: 1,285,007\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "model_rv = Model(inputs=inputs, outputs=predictions) # specify what is network input, and what is network output\n",
    "model_rv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4cece05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rv.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0894dc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 2s 56ms/step - loss: 1.2962 - accuracy: 0.5415 - val_loss: 0.3294 - val_accuracy: 0.8464\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 1s 47ms/step - loss: 0.6286 - accuracy: 0.7705 - val_loss: 0.0805 - val_accuracy: 0.9750\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 1s 46ms/step - loss: 0.5044 - accuracy: 0.8165 - val_loss: 0.0351 - val_accuracy: 0.9929\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 1s 48ms/step - loss: 0.4291 - accuracy: 0.8496 - val_loss: 0.0393 - val_accuracy: 0.9929\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 1s 50ms/step - loss: 0.3779 - accuracy: 0.8723 - val_loss: 0.0350 - val_accuracy: 0.9929\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 1s 46ms/step - loss: 0.3148 - accuracy: 0.8942 - val_loss: 0.0378 - val_accuracy: 0.9929\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 1s 47ms/step - loss: 0.2985 - accuracy: 0.8960 - val_loss: 0.0347 - val_accuracy: 0.9929\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 1s 46ms/step - loss: 0.2742 - accuracy: 0.9009 - val_loss: 0.0385 - val_accuracy: 0.9929\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 1s 46ms/step - loss: 0.2482 - accuracy: 0.9134 - val_loss: 0.0347 - val_accuracy: 0.9929\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 1s 49ms/step - loss: 0.2410 - accuracy: 0.9152 - val_loss: 0.0353 - val_accuracy: 0.9929\n",
      "Epoch 10: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22416cb4850>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss',  patience=3, verbose=1)\n",
    "# stop if loss does not improve for 3 iterations\n",
    "\n",
    "model_rv.fit(concat[:split_point], y_train[:split_point], batch_size=128, epochs=30, \n",
    "              validation_data=(concat[split_point:], y_train[split_point:]), callbacks=[early_stop], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef692a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rv.save('model_rv.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "508e3e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_prediction = []\n",
    "for files in os.listdir('./Data/Test_2'):\n",
    "\n",
    "    if files== 'desktop.ini':\n",
    "        pass\n",
    "    else:    \n",
    "        test_img = get_image(f'./Data/Test_2/{files}')\n",
    "        image_batch = np.expand_dims(test_img, axis=0)\n",
    "        image_batch = np.copy(image_batch)\n",
    "        \n",
    "        image_batch1 = resnet50.preprocess_input(image_batch.copy())\n",
    "        image_batch2 = vgg16.preprocess_input(image_batch.copy())\n",
    "        feature_input1 = resnet50_model.predict(image_batch1)\n",
    "        feature_input2 = vgg16_model.predict(image_batch2)\n",
    "        concat2 = np.concatenate([feature_input1,feature_input2],axis=3)\n",
    "        predictions = model_rv.predict(concat2)\n",
    "        pos = np.argmax(predictions)\n",
    "        Test_prediction.append(pos)\n",
    "\n",
    "        #print('Image Name: ',files,' Prediction: ',types[pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e96ea036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.775\n"
     ]
    }
   ],
   "source": [
    "y_test = pd.read_excel(r'./Data/test_2_label.xlsx',usecols=[1,1])\n",
    "y_test = y_test.to_numpy()\n",
    "y_test = np.squeeze(y_test)\n",
    "test_acc = (Test_prediction == y_test).mean()\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a065b6e",
   "metadata": {},
   "source": [
    "# concatenating with Activation = Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5389724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 215s 5s/step\n",
      "(2520, 7, 7, 2048)\n",
      "40/40 [==============================] - 520s 13s/step\n",
      "(2520, 7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "resnet50_x_train_sig = resnet50.preprocess_input(x_train.copy())\n",
    "resnet50_model_sig = resnet50.ResNet50(weights='imagenet', include_top=False)\n",
    "resnet50_features_sig = resnet50_model_sig.predict(resnet50_x_train_sig, batch_size=64, verbose=1)\n",
    "print(resnet50_features_sig.shape)\n",
    "\n",
    "#vgg16\n",
    "vgg16_x_train_sig = vgg16.preprocess_input(x_train.copy())\n",
    "vgg16_model_sig = vgg16.VGG16(weights='imagenet', include_top=False)\n",
    "vgg16_features_sig = vgg16_model_sig.predict(vgg16_x_train_sig, batch_size=64, verbose=1)\n",
    "print(vgg16_features_sig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "892d2ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2520, 7, 7, 2560)\n"
     ]
    }
   ],
   "source": [
    "concat_sig = np.concatenate([resnet50_features_sig, vgg16_features_sig],axis=3)\n",
    "print(concat_sig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3121e479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2560)\n",
      "(None, 7)\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape = (7, 7, 2560)) # to take 7 x 7 x 2048 images\n",
    "x = GlobalAveragePooling2D()(inputs) # to convert to 2048 feagures\n",
    "print(x.shape)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "x = Dense(500)(x) # add a dense layer, but not adding activation so that we can add batch-norm first\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"sigmoid\")(x)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "# Softmax layer to the output classes\n",
    "predictions = Dense(num_classes, activation='softmax')(x) # arg1 is: units = dimensionality of the output space.\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "187728ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 7, 7, 2560)]      0         \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 2560)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 2560)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 500)               1280500   \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 500)              2000      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 500)               0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 7)                 3507      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,286,007\n",
      "Trainable params: 1,285,007\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_rv_sig = Model(inputs=inputs, outputs=predictions) # specify what is network input, and what is network output\n",
    "model_rv_sig.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fbf69f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rv_sig.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dcb39d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 3s 126ms/step - loss: 1.4664 - accuracy: 0.4643 - val_loss: 1.6209 - val_accuracy: 0.3750\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 1s 54ms/step - loss: 0.8558 - accuracy: 0.6938 - val_loss: 0.2460 - val_accuracy: 0.9286\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 1s 48ms/step - loss: 0.6620 - accuracy: 0.7701 - val_loss: 0.1383 - val_accuracy: 0.9643\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 1s 47ms/step - loss: 0.5709 - accuracy: 0.8018 - val_loss: 0.1008 - val_accuracy: 0.9821\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 0.5135 - accuracy: 0.8241 - val_loss: 0.1014 - val_accuracy: 0.9821\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 1s 48ms/step - loss: 0.4442 - accuracy: 0.8536 - val_loss: 0.0571 - val_accuracy: 0.9929\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 1s 50ms/step - loss: 0.3955 - accuracy: 0.8679 - val_loss: 0.0658 - val_accuracy: 0.9929\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 0.3875 - accuracy: 0.8687 - val_loss: 0.0548 - val_accuracy: 0.9929\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 1s 48ms/step - loss: 0.3528 - accuracy: 0.8866 - val_loss: 0.0708 - val_accuracy: 0.9893\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 1s 47ms/step - loss: 0.3235 - accuracy: 0.8951 - val_loss: 0.0650 - val_accuracy: 0.9929\n",
      "Epoch 11/30\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.3033 - accuracy: 0.8938 - val_loss: 0.0620 - val_accuracy: 0.9929\n",
      "Epoch 11: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22421cf4a60>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',  patience=3, verbose=1)\n",
    "# stop if loss does not improve for 3 iterations\n",
    "\n",
    "model_rv_sig.fit(concat_sig[:split_point], y_train[:split_point], batch_size=128, epochs=30, \n",
    "              validation_data=(concat_sig[split_point:], y_train[split_point:]), callbacks=[early_stop], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7f8e172",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rv_sig.save('model_rv_sig.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77496f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_prediction2 = []\n",
    "for files in os.listdir('./Data/Test_2'):\n",
    "\n",
    "    if files== 'desktop.ini':\n",
    "        pass\n",
    "    else:    \n",
    "        test_img = get_image(f'./Data/Test_2/{files}')\n",
    "        image_batch = np.expand_dims(test_img, axis=0)\n",
    "        image_batch = np.copy(image_batch)\n",
    "        \n",
    "        image_batch1 = resnet50.preprocess_input(image_batch.copy())\n",
    "        image_batch2 = vgg16.preprocess_input(image_batch.copy())\n",
    "        feature_input1 = resnet50_model_sig.predict(image_batch1)\n",
    "        feature_input2 = vgg16_model_sig.predict(image_batch2)\n",
    "        concat2 = np.concatenate([feature_input1,feature_input2],axis=3)\n",
    "        predictions = model_rv_sig.predict(concat2)\n",
    "        pos = np.argmax(predictions)\n",
    "        Test_prediction2.append(pos)\n",
    "\n",
    "        #print('Image Name: ',files,' Prediction: ',types[pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c78888f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.775\n"
     ]
    }
   ],
   "source": [
    "test_acc = (Test_prediction == y_test).mean()\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6c7611",
   "metadata": {},
   "source": [
    "# concatenating Activation = Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82e08b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 194s 5s/step\n",
      "(2520, 7, 7, 2048)\n",
      "40/40 [==============================] - 470s 12s/step\n",
      "(2520, 7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "#Resnet50 - last layer of features\n",
    "resnet50_x_train_th = resnet50.preprocess_input(x_train.copy())\n",
    "resnet50_model_th = resnet50.ResNet50(weights='imagenet', include_top=False)\n",
    "resnet50_features_th = resnet50_model_th.predict(resnet50_x_train_th, batch_size=64, verbose=1)\n",
    "print(resnet50_features_th.shape)\n",
    "\n",
    "#vgg16\n",
    "vgg16_x_train_th = vgg16.preprocess_input(x_train.copy())\n",
    "vgg16_model_th = vgg16.VGG16(weights='imagenet', include_top=False)\n",
    "vgg16_features_th = vgg16_model_th.predict(vgg16_x_train_th, batch_size=64, verbose=1)\n",
    "print(vgg16_features_th.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "588e8ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2520, 7, 7, 2560)\n"
     ]
    }
   ],
   "source": [
    "concat_th = np.concatenate([resnet50_features_th, vgg16_features_th],axis=3)\n",
    "print(concat_th.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20a8a245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2560)\n",
      "(None, 7)\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape = (7, 7, 2560)) # to take 7 x 7 x 2048 images\n",
    "x = GlobalAveragePooling2D()(inputs) # to convert to 2048 feagures\n",
    "print(x.shape)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "x = Dense(500)(x) # add a dense layer, but not adding activation so that we can add batch-norm first\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"tanh\")(x)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "# Softmax layer to the output classes\n",
    "predictions = Dense(num_classes, activation='softmax')(x) # arg1 is: units = dimensionality of the output space.\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bdc3007c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 7, 7, 2560)]      0         \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 2560)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 2560)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 500)               1280500   \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 500)              2000      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 500)               0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 7)                 3507      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,286,007\n",
      "Trainable params: 1,285,007\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_rv_th = Model(inputs=inputs, outputs=predictions) # specify what is network input, and what is network output\n",
    "model_rv_th.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "090f0f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rv_th.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d90a9773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 2s 59ms/step - loss: 1.2043 - accuracy: 0.5750 - val_loss: 0.2068 - val_accuracy: 0.9107\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 1s 49ms/step - loss: 0.5803 - accuracy: 0.8054 - val_loss: 0.0364 - val_accuracy: 0.9964\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.4411 - accuracy: 0.8464 - val_loss: 0.0458 - val_accuracy: 0.9929\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 1s 46ms/step - loss: 0.3539 - accuracy: 0.8835 - val_loss: 0.0304 - val_accuracy: 0.9929\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 1s 46ms/step - loss: 0.3456 - accuracy: 0.8763 - val_loss: 0.0234 - val_accuracy: 0.9929\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 1s 47ms/step - loss: 0.2896 - accuracy: 0.9045 - val_loss: 0.0239 - val_accuracy: 0.9929\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 1s 48ms/step - loss: 0.2788 - accuracy: 0.8982 - val_loss: 0.0344 - val_accuracy: 0.9929\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 1s 47ms/step - loss: 0.2492 - accuracy: 0.9076 - val_loss: 0.0322 - val_accuracy: 0.9929\n",
      "Epoch 8: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22423b169d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',  patience=3, verbose=1)\n",
    "# stop if loss does not improve for 3 iterations\n",
    "\n",
    "model_rv_th.fit(concat_th[:split_point], y_train[:split_point], batch_size=128, epochs=30, \n",
    "              validation_data=(concat_th[split_point:], y_train[split_point:]), callbacks=[early_stop], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1af1637b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rv_th.save('model_rv_th.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "070835e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_prediction = []\n",
    "for files in os.listdir('./Data/Test_2'):\n",
    "\n",
    "    if files== 'desktop.ini':\n",
    "        pass\n",
    "    else:    \n",
    "        test_img = get_image(f'./Data/Test_2/{files}')\n",
    "        image_batch = np.expand_dims(test_img, axis=0)\n",
    "        image_batch = np.copy(image_batch)\n",
    "        \n",
    "        image_batch1 = resnet50.preprocess_input(image_batch.copy())\n",
    "        image_batch2 = vgg16.preprocess_input(image_batch.copy())\n",
    "        feature_input1 = resnet50_model_th.predict(image_batch1)\n",
    "        feature_input2 = vgg16_model_th.predict(image_batch2)\n",
    "        concat2 = np.concatenate([feature_input1,feature_input2],axis=3)\n",
    "        predictions = model_rv_th.predict(concat2)\n",
    "        pos = np.argmax(predictions)\n",
    "        Test_prediction.append(pos)\n",
    "\n",
    "        #print('Image Name: ',files,' Prediction: ',types[pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "076b76ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.7678571428571429\n"
     ]
    }
   ],
   "source": [
    "test_acc = (Test_prediction == y_test).mean()\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c6d827",
   "metadata": {},
   "source": [
    "# concatenating with Activation = softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e5d49d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 220s 5s/step\n",
      "(2520, 7, 7, 2048)\n",
      "40/40 [==============================] - 509s 13s/step\n",
      "(2520, 7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "#Resnet50 - last layer of features\n",
    "resnet50_x_train_s = resnet50.preprocess_input(x_train.copy())\n",
    "resnet50_model_s = resnet50.ResNet50(weights='imagenet', include_top=False)\n",
    "resnet50_features_s = resnet50_model_s.predict(resnet50_x_train_s, batch_size=64, verbose=1)\n",
    "print(resnet50_features_s.shape)\n",
    "\n",
    "#vgg16\n",
    "vgg16_x_train_s = vgg16.preprocess_input(x_train.copy())\n",
    "vgg16_model_s = vgg16.VGG16(weights='imagenet', include_top=False)\n",
    "vgg16_features_s = vgg16_model_s.predict(vgg16_x_train_s, batch_size=64, verbose=1)\n",
    "print(vgg16_features_s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dbde0fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2520, 7, 7, 2560)\n"
     ]
    }
   ],
   "source": [
    "concat_s = np.concatenate([resnet50_features_s, vgg16_features_s],axis=3)\n",
    "print(concat_s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f0d4faaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2560)\n",
      "(None, 7)\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape = (7, 7, 2560)) # to take 7 x 7 x 2048 images\n",
    "x = GlobalAveragePooling2D()(inputs) # to convert to 2048 feagures\n",
    "print(x.shape)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "x = Dense(500)(x) # add a dense layer, but not adding activation so that we can add batch-norm first\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"softmax\")(x)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "# Softmax layer to the output classes\n",
    "predictions = Dense(num_classes, activation='softmax')(x) # arg1 is: units = dimensionality of the output space.\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "70c87a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 7, 7, 2560)]      0         \n",
      "                                                                 \n",
      " global_average_pooling2d_4   (None, 2560)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 2560)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 500)               1280500   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 500)              2000      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 500)               0         \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 7)                 3507      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,286,007\n",
      "Trainable params: 1,285,007\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_rv_s = Model(inputs=inputs, outputs=predictions) # specify what is network input, and what is network output\n",
    "model_rv_s.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "da90500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rv_s.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "56d71419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 3s 64ms/step - loss: 1.9338 - accuracy: 0.4009 - val_loss: 1.9518 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 1.9144 - accuracy: 0.6031 - val_loss: 1.9771 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 1s 53ms/step - loss: 1.8977 - accuracy: 0.6687 - val_loss: 2.0005 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 1s 53ms/step - loss: 1.8807 - accuracy: 0.7201 - val_loss: 2.0150 - val_accuracy: 0.0000e+00\n",
      "Epoch 4: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22435e79a60>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',  patience=3, verbose=1)\n",
    "# stop if loss does not improve for 3 iterations\n",
    "\n",
    "model_rv_s.fit(concat_s[:split_point], y_train[:split_point], batch_size=128, epochs=30, \n",
    "              validation_data=(concat_s[split_point:], y_train[split_point:]), callbacks=[early_stop], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "057115aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rv_s.save('model_rv_s.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "367b8e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_prediction = []\n",
    "for files in os.listdir('./Data/Test_2'):\n",
    "\n",
    "    if files== 'desktop.ini':\n",
    "        pass\n",
    "    else:    \n",
    "        test_img = get_image(f'./Data/Test_2/{files}')\n",
    "        image_batch = np.expand_dims(test_img, axis=0)\n",
    "        image_batch = np.copy(image_batch)\n",
    "        \n",
    "        image_batch1 = resnet50.preprocess_input(image_batch.copy())\n",
    "        image_batch2 = vgg16.preprocess_input(image_batch.copy())\n",
    "        feature_input1 = resnet50_model_s.predict(image_batch1)\n",
    "        feature_input2 = vgg16_model_s.predict(image_batch2)\n",
    "        concat2 = np.concatenate([feature_input1,feature_input2],axis=3)\n",
    "        predictions = model_rv_s.predict(concat2)\n",
    "        pos = np.argmax(predictions)\n",
    "        Test_prediction.append(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5869bef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.4607142857142857\n"
     ]
    }
   ],
   "source": [
    "test_acc = (Test_prediction == y_test).mean()\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cc6675",
   "metadata": {},
   "source": [
    "# Contatenating with Activation = elu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcf7df9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 206s 5s/step\n",
      "(2520, 7, 7, 2048)\n",
      "40/40 [==============================] - 538s 13s/step\n",
      "(2520, 7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import inception_v3\n",
    "from tensorflow.keras.applications import vgg16\n",
    "\n",
    "resnet50_x_train_elu = resnet50.preprocess_input(x_train.copy())\n",
    "resnet50_model_elu = resnet50.ResNet50(weights='imagenet', include_top=False)\n",
    "resnet50_features_elu = resnet50_model_elu.predict(resnet50_x_train_elu, batch_size=64, verbose=1)\n",
    "print(resnet50_features_elu.shape)\n",
    "\n",
    "#vgg16\n",
    "vgg16_x_train_elu = vgg16.preprocess_input(x_train.copy())\n",
    "vgg16_model_elu = vgg16.VGG16(weights='imagenet', include_top=False)\n",
    "vgg16_features_elu = vgg16_model_elu.predict(vgg16_x_train_elu, batch_size=64, verbose=1)\n",
    "print(vgg16_features_elu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b043605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2520, 7, 7, 2560)\n"
     ]
    }
   ],
   "source": [
    "concat_elu = np.concatenate([resnet50_features_elu, vgg16_features_elu],axis=3)\n",
    "print(concat_elu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aedfbc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2560)\n",
      "(None, 7)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout, Activation, BatchNormalization\n",
    "\n",
    "inputs = Input(shape = (7, 7, 2560)) # to take 7 x 7 x 2048 images\n",
    "x = GlobalAveragePooling2D()(inputs) # to convert to 2048 feagures\n",
    "print(x.shape)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "x = Dense(500)(x) # add a dense layer, but not adding activation so that we can add batch-norm first\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"elu\")(x)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "# Softmax layer to the output classes\n",
    "predictions = Dense(num_classes, activation='softmax')(x) # arg1 is: units = dimensionality of the output space.\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d159467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 7, 7, 2560)]      0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2560)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2560)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 500)               1280500   \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 500)              2000      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 500)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 3507      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,286,007\n",
      "Trainable params: 1,285,007\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "model_rv_elu = Model(inputs=inputs, outputs=predictions) # specify what is network input, and what is network output\n",
    "model_rv_elu.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9240f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rv_elu.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c525d14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 4s 82ms/step - loss: 1.3333 - accuracy: 0.5527 - val_loss: 0.4050 - val_accuracy: 0.8107\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.6092 - accuracy: 0.7902 - val_loss: 0.0249 - val_accuracy: 0.9964\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 1s 55ms/step - loss: 0.4412 - accuracy: 0.8482 - val_loss: 0.0175 - val_accuracy: 0.9929\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 1s 53ms/step - loss: 0.3882 - accuracy: 0.8576 - val_loss: 0.0236 - val_accuracy: 0.9929\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 1s 53ms/step - loss: 0.3443 - accuracy: 0.8795 - val_loss: 0.0408 - val_accuracy: 0.9929\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.2955 - accuracy: 0.8987 - val_loss: 0.0303 - val_accuracy: 0.9929\n",
      "Epoch 6: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21b2b83ddc0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss',  patience=3, verbose=1)\n",
    "# stop if loss does not improve for 3 iterations\n",
    "\n",
    "model_rv_elu.fit(concat_elu[:split_point], y_train[:split_point], batch_size=128, epochs=30, \n",
    "              validation_data=(concat_elu[split_point:], y_train[split_point:]), callbacks=[early_stop], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa3de79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rv_elu.save('model_rv_elu.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65482cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_prediction = []\n",
    "for files in os.listdir('./Data/Test_2'):\n",
    "\n",
    "    if files== 'desktop.ini':\n",
    "        pass\n",
    "    else:    \n",
    "        test_img = get_image(f'./Data/Test_2/{files}')\n",
    "        image_batch = np.expand_dims(test_img, axis=0)\n",
    "        image_batch = np.copy(image_batch)\n",
    "        \n",
    "        image_batch1 = resnet50.preprocess_input(image_batch.copy())\n",
    "        image_batch2 = vgg16.preprocess_input(image_batch.copy())\n",
    "        feature_input1 = resnet50_model_elu.predict(image_batch1)\n",
    "        feature_input2 = vgg16_model_elu.predict(image_batch2)\n",
    "        concat2 = np.concatenate([feature_input1,feature_input2],axis=3)\n",
    "        predictions = model_rv_elu.predict(concat2)\n",
    "        pos = np.argmax(predictions)\n",
    "        Test_prediction.append(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f54517f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.775\n"
     ]
    }
   ],
   "source": [
    "y_test = pd.read_excel(r'./Data/test_2_label.xlsx',usecols=[1,1])\n",
    "y_test = y_test.to_numpy()\n",
    "y_test = np.squeeze(y_test)\n",
    "test_acc = (Test_prediction == y_test).mean()\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10007ac2",
   "metadata": {},
   "source": [
    "# concatenatin with Activation = exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d07481c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 219s 5s/step\n",
      "(2520, 7, 7, 2048)\n",
      "40/40 [==============================] - 526s 13s/step\n",
      "(2520, 7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "#Resnet50 - last layer of features\n",
    "resnet50_x_train_expo = resnet50.preprocess_input(x_train.copy())\n",
    "resnet50_model_expo = resnet50.ResNet50(weights='imagenet', include_top=False)\n",
    "resnet50_features_expo = resnet50_model_expo.predict(resnet50_x_train_expo, batch_size=64, verbose=1)\n",
    "print(resnet50_features_expo.shape)\n",
    "\n",
    "#vgg16\n",
    "vgg16_x_train_expo = vgg16.preprocess_input(x_train.copy())\n",
    "vgg16_model_expo = vgg16.VGG16(weights='imagenet', include_top=False)\n",
    "vgg16_features_expo = vgg16_model_expo.predict(vgg16_x_train_expo, batch_size=64, verbose=1)\n",
    "print(vgg16_features_expo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a7d1ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2520, 7, 7, 2560)\n"
     ]
    }
   ],
   "source": [
    "concat_expo = np.concatenate([resnet50_features_expo, vgg16_features_expo],axis=3)\n",
    "print(concat_expo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d78e9704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2560)\n",
      "(None, 7)\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape = (7, 7, 2560)) # to take 7 x 7 x 2048 images\n",
    "x = GlobalAveragePooling2D()(inputs) # to convert to 2048 feagures\n",
    "print(x.shape)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "x = Dense(500)(x) # add a dense layer, but not adding activation so that we can add batch-norm first\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"exponential\")(x)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "# Softmax layer to the output classes\n",
    "predictions = Dense(num_classes, activation='softmax')(x) # arg1 is: units = dimensionality of the output space.\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e18faddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 7, 7, 2560)]      0         \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 2560)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 2560)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 500)               1280500   \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 500)              2000      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 500)               0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 7)                 3507      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,286,007\n",
      "Trainable params: 1,285,007\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_rv_expo = Model(inputs=inputs, outputs=predictions) # specify what is network input, and what is network output\n",
    "model_rv_expo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99246a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rv_expo.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7dd0b8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 3s 76ms/step - loss: 3.4225 - accuracy: 0.4415 - val_loss: 1.7831 - val_accuracy: 0.8357\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 1s 56ms/step - loss: 1.5049 - accuracy: 0.6902 - val_loss: 0.1227 - val_accuracy: 0.9821\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 1.1931 - accuracy: 0.7353 - val_loss: 0.0566 - val_accuracy: 0.9964\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 1.0028 - accuracy: 0.7656 - val_loss: 0.0465 - val_accuracy: 0.9929\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 1s 53ms/step - loss: 0.9389 - accuracy: 0.8076 - val_loss: 0.0422 - val_accuracy: 0.9929\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 1s 53ms/step - loss: 0.6966 - accuracy: 0.8179 - val_loss: 0.0534 - val_accuracy: 0.9929\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 1s 54ms/step - loss: 0.6150 - accuracy: 0.8357 - val_loss: 0.0612 - val_accuracy: 0.9929\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 1s 54ms/step - loss: 0.6192 - accuracy: 0.8371 - val_loss: 0.0597 - val_accuracy: 0.9929\n",
      "Epoch 8: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21b2e2424c0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',  patience=3, verbose=1)\n",
    "# stop if loss does not improve for 3 iterations\n",
    "\n",
    "model_rv_expo.fit(concat_expo[:split_point], y_train[:split_point], batch_size=128, epochs=30, \n",
    "              validation_data=(concat_expo[split_point:], y_train[split_point:]), callbacks=[early_stop], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2559b7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rv_expo.save('model_rv_expo.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "355b32ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_prediction = []\n",
    "for files in os.listdir('./Data/Test_2'):\n",
    "\n",
    "    if files== 'desktop.ini':\n",
    "        pass\n",
    "    else:    \n",
    "        test_img = get_image(f'./Data/Test_2/{files}')\n",
    "        image_batch = np.expand_dims(test_img, axis=0)\n",
    "        image_batch = np.copy(image_batch)\n",
    "        \n",
    "        image_batch1 = resnet50.preprocess_input(image_batch.copy())\n",
    "        image_batch2 = vgg16.preprocess_input(image_batch.copy())\n",
    "        feature_input1 = resnet50_model_expo.predict(image_batch1)\n",
    "        feature_input2 = vgg16_model_expo.predict(image_batch2)\n",
    "        concat2 = np.concatenate([feature_input1,feature_input2],axis=3)\n",
    "        predictions = model_rv_expo.predict(concat2)\n",
    "        pos = np.argmax(predictions)\n",
    "        Test_prediction.append(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "043c2a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.7607142857142857\n"
     ]
    }
   ],
   "source": [
    "test_acc = (Test_prediction == y_test).mean()\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58225607",
   "metadata": {},
   "source": [
    "# concatenating with Optimizer = SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed4f7071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 230s 6s/step\n",
      "(2520, 7, 7, 2048)\n",
      "40/40 [==============================] - 454s 11s/step\n",
      "(2520, 7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "#Resnet50 - last layer of features\n",
    "resnet50_x_train_sgd = resnet50.preprocess_input(x_train.copy())\n",
    "resnet50_model_sgd = resnet50.ResNet50(weights='imagenet', include_top=False)\n",
    "resnet50_features_sgd = resnet50_model_sgd.predict(resnet50_x_train_sgd, batch_size=64, verbose=1)\n",
    "print(resnet50_features_sgd.shape)\n",
    "\n",
    "#vgg16\n",
    "vgg16_x_train_sgd = vgg16.preprocess_input(x_train.copy())\n",
    "vgg16_model_sgd = vgg16.VGG16(weights='imagenet', include_top=False)\n",
    "vgg16_features_sgd = vgg16_model_sgd.predict(vgg16_x_train_sgd, batch_size=64, verbose=1)\n",
    "print(vgg16_features_sgd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "16bd38b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2520, 7, 7, 2560)\n"
     ]
    }
   ],
   "source": [
    "concat_sgd = np.concatenate([resnet50_features_sgd, vgg16_features_sgd],axis=3)\n",
    "print(concat_sgd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ace7c25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2560)\n",
      "(None, 7)\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape = (7, 7, 2560)) # to take 7 x 7 x 2048 images\n",
    "x = GlobalAveragePooling2D()(inputs) # to convert to 2048 feagures\n",
    "print(x.shape)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "x = Dense(500)(x) # add a dense layer, but not adding activation so that we can add batch-norm first\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "# Softmax layer to the output classes\n",
    "predictions = Dense(num_classes, activation='softmax')(x) # arg1 is: units = dimensionality of the output space.\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a4faa82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 7, 7, 2560)]      0         \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 2560)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 2560)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 500)               1280500   \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 500)              2000      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 500)               0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 7)                 3507      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,286,007\n",
      "Trainable params: 1,285,007\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_rv_sgd = Model(inputs=inputs, outputs=predictions) # specify what is network input, and what is network output\n",
    "model_rv_sgd.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "47599c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rv_sgd.compile(loss='categorical_crossentropy', optimizer=\"sgd\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8fdd0366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 3s 55ms/step - loss: 2.0695 - accuracy: 0.2799 - val_loss: 3.9133 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 1.6647 - accuracy: 0.3938 - val_loss: 2.9791 - val_accuracy: 0.0143\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 1.5576 - accuracy: 0.4263 - val_loss: 2.3822 - val_accuracy: 0.0643\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 1.3922 - accuracy: 0.4759 - val_loss: 1.8582 - val_accuracy: 0.2393\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 1.3081 - accuracy: 0.5210 - val_loss: 1.4058 - val_accuracy: 0.4643\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 1.2659 - accuracy: 0.5330 - val_loss: 1.1260 - val_accuracy: 0.5893\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 1.2102 - accuracy: 0.5509 - val_loss: 1.0465 - val_accuracy: 0.6571\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 1.1649 - accuracy: 0.5759 - val_loss: 0.9267 - val_accuracy: 0.7214\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 1s 46ms/step - loss: 1.1219 - accuracy: 0.5884 - val_loss: 0.7680 - val_accuracy: 0.8036\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 1.1070 - accuracy: 0.5875 - val_loss: 0.7543 - val_accuracy: 0.8321\n",
      "Epoch 11/30\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 1.0621 - accuracy: 0.5955 - val_loss: 0.6681 - val_accuracy: 0.8321\n",
      "Epoch 12/30\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 1.0113 - accuracy: 0.6272 - val_loss: 0.6704 - val_accuracy: 0.8429\n",
      "Epoch 13/30\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.9908 - accuracy: 0.6348 - val_loss: 0.6769 - val_accuracy: 0.8464\n",
      "Epoch 14/30\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.9603 - accuracy: 0.6576 - val_loss: 0.6300 - val_accuracy: 0.8571\n",
      "Epoch 15/30\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.9415 - accuracy: 0.6554 - val_loss: 0.5102 - val_accuracy: 0.9179\n",
      "Epoch 16/30\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.9484 - accuracy: 0.6513 - val_loss: 0.5103 - val_accuracy: 0.9179\n",
      "Epoch 17/30\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.8826 - accuracy: 0.6772 - val_loss: 0.5219 - val_accuracy: 0.9000\n",
      "Epoch 18/30\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.8952 - accuracy: 0.6772 - val_loss: 0.4937 - val_accuracy: 0.9071\n",
      "Epoch 19/30\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.8640 - accuracy: 0.6795 - val_loss: 0.4394 - val_accuracy: 0.9536\n",
      "Epoch 20/30\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.8476 - accuracy: 0.6857 - val_loss: 0.4173 - val_accuracy: 0.9571\n",
      "Epoch 21/30\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.8658 - accuracy: 0.6790 - val_loss: 0.3705 - val_accuracy: 0.9643\n",
      "Epoch 22/30\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.8254 - accuracy: 0.7080 - val_loss: 0.3316 - val_accuracy: 0.9679\n",
      "Epoch 23/30\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.8319 - accuracy: 0.6879 - val_loss: 0.3039 - val_accuracy: 0.9786\n",
      "Epoch 24/30\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.8180 - accuracy: 0.6920 - val_loss: 0.3332 - val_accuracy: 0.9714\n",
      "Epoch 25/30\n",
      "18/18 [==============================] - 1s 47ms/step - loss: 0.7935 - accuracy: 0.7161 - val_loss: 0.2868 - val_accuracy: 0.9821\n",
      "Epoch 26/30\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.7658 - accuracy: 0.7210 - val_loss: 0.2634 - val_accuracy: 0.9821\n",
      "Epoch 27/30\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.7421 - accuracy: 0.7210 - val_loss: 0.2619 - val_accuracy: 0.9821\n",
      "Epoch 28/30\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.7531 - accuracy: 0.7246 - val_loss: 0.2551 - val_accuracy: 0.9821\n",
      "Epoch 29/30\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.7238 - accuracy: 0.7393 - val_loss: 0.2442 - val_accuracy: 0.9821\n",
      "Epoch 30/30\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.7411 - accuracy: 0.7281 - val_loss: 0.2184 - val_accuracy: 0.9821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21b2f3c2c40>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',  patience=3, verbose=1)\n",
    "# stop if loss does not improve for 3 iterations\n",
    "\n",
    "model_rv_sgd.fit(concat_sgd[:split_point], y_train[:split_point], batch_size=128, epochs=30, \n",
    "              validation_data=(concat_sgd[split_point:], y_train[split_point:]), callbacks=[early_stop], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5796cb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rv_sgd.save('model_rv_sgd.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "88648c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_prediction = []\n",
    "for files in os.listdir('./Data/Test_2'):\n",
    "\n",
    "    if files== 'desktop.ini':\n",
    "        pass\n",
    "    else:    \n",
    "        test_img = get_image(f'./Data/Test_2/{files}')\n",
    "        image_batch = np.expand_dims(test_img, axis=0)\n",
    "        image_batch = np.copy(image_batch)\n",
    "        \n",
    "        image_batch1 = resnet50.preprocess_input(image_batch.copy())\n",
    "        image_batch2 = vgg16.preprocess_input(image_batch.copy())\n",
    "        feature_input1 = resnet50_model_sgd.predict(image_batch1)\n",
    "        feature_input2 = vgg16_model_sgd.predict(image_batch2)\n",
    "        concat2 = np.concatenate([feature_input1,feature_input2],axis=3)\n",
    "        predictions = model_rv_sgd.predict(concat2)\n",
    "        pos = np.argmax(predictions)\n",
    "        Test_prediction.append(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "afbeab3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.7464285714285714\n"
     ]
    }
   ],
   "source": [
    "test_acc = (Test_prediction == y_test).mean()\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba2dadc",
   "metadata": {},
   "source": [
    "# concatenating with Optimizer = RMS*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "16497a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 206s 5s/step\n",
      "(2520, 7, 7, 2048)\n",
      "40/40 [==============================] - 460s 11s/step\n",
      "(2520, 7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "#Resnet50 - last layer of features\n",
    "resnet50_x_train_rms = resnet50.preprocess_input(x_train.copy())\n",
    "resnet50_model_rms = resnet50.ResNet50(weights='imagenet', include_top=False)\n",
    "resnet50_features_rms = resnet50_model_rms.predict(resnet50_x_train_rms, batch_size=64, verbose=1)\n",
    "print(resnet50_features_rms.shape)\n",
    "\n",
    "#vgg16\n",
    "vgg16_x_train_rms = vgg16.preprocess_input(x_train.copy())\n",
    "vgg16_model_rms = vgg16.VGG16(weights='imagenet', include_top=False)\n",
    "vgg16_features_rms = vgg16_model_rms.predict(vgg16_x_train_rms, batch_size=64, verbose=1)\n",
    "print(vgg16_features_rms.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "813cd967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2520, 7, 7, 2560)\n"
     ]
    }
   ],
   "source": [
    "concat_rms = np.concatenate([resnet50_features_rms, vgg16_features_rms],axis=3)\n",
    "print(concat_rms.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1cb12894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2560)\n",
      "(None, 7)\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape = (7, 7, 2560)) # to take 7 x 7 x 2048 images\n",
    "x = GlobalAveragePooling2D()(inputs) # to convert to 2048 feagures\n",
    "print(x.shape)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "x = Dense(500)(x) # add a dense layer, but not adding activation so that we can add batch-norm first\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "# Softmax layer to the output classes\n",
    "predictions = Dense(num_classes, activation='softmax')(x) # arg1 is: units = dimensionality of the output space.\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f2143a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 7, 7, 2560)]      0         \n",
      "                                                                 \n",
      " global_average_pooling2d_3   (None, 2560)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 2560)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 500)               1280500   \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 500)              2000      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 500)               0         \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 7)                 3507      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,286,007\n",
      "Trainable params: 1,285,007\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_rv_rms = Model(inputs=inputs, outputs=predictions) # specify what is network input, and what is network output\n",
    "model_rv_rms.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4342394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rv_rms.compile(loss='categorical_crossentropy', optimizer=\"RMSprop\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0a6a9e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 3s 65ms/step - loss: 1.1114 - accuracy: 0.6080 - val_loss: 0.0739 - val_accuracy: 0.9821\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 0.5978 - accuracy: 0.7875 - val_loss: 0.0716 - val_accuracy: 0.9821\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 1s 48ms/step - loss: 0.4948 - accuracy: 0.8277 - val_loss: 0.0607 - val_accuracy: 0.9714\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 1s 49ms/step - loss: 0.3994 - accuracy: 0.8665 - val_loss: 0.0476 - val_accuracy: 0.9929\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 1s 50ms/step - loss: 0.3622 - accuracy: 0.8710 - val_loss: 0.0320 - val_accuracy: 0.9929\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 0.3075 - accuracy: 0.8978 - val_loss: 0.0463 - val_accuracy: 0.9929\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 0.2776 - accuracy: 0.9058 - val_loss: 0.0357 - val_accuracy: 0.9929\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 1s 54ms/step - loss: 0.2784 - accuracy: 0.9004 - val_loss: 0.0381 - val_accuracy: 0.9929\n",
      "Epoch 8: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21b3fe9ca30>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',  patience=3, verbose=1)\n",
    "# stop if loss does not improve for 3 iterations\n",
    "\n",
    "model_rv_rms.fit(concat_rms[:split_point], y_train[:split_point], batch_size=128, epochs=30, \n",
    "              validation_data=(concat_rms[split_point:], y_train[split_point:]), callbacks=[early_stop], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5b7a2d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rv_rms.save('model_rv_rms.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "178acfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_prediction = []\n",
    "for files in os.listdir('./Data/Test_2'):\n",
    "\n",
    "    if files== 'desktop.ini':\n",
    "        pass\n",
    "    else:    \n",
    "        test_img = get_image(f'./Data/Test_2/{files}')\n",
    "        image_batch = np.expand_dims(test_img, axis=0)\n",
    "        image_batch = np.copy(image_batch)\n",
    "        \n",
    "        image_batch1 = resnet50.preprocess_input(image_batch.copy())\n",
    "        image_batch2 = vgg16.preprocess_input(image_batch.copy())\n",
    "        feature_input1 = resnet50_model_rms.predict(image_batch1)\n",
    "        feature_input2 = vgg16_model_rms.predict(image_batch2)\n",
    "        concat2 = np.concatenate([feature_input1,feature_input2],axis=3)\n",
    "        predictions = model_rv_rms.predict(concat2)\n",
    "        pos = np.argmax(predictions)\n",
    "        Test_prediction.append(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6aa415ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.7607142857142857\n"
     ]
    }
   ],
   "source": [
    "test_acc = (Test_prediction == y_test).mean()\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b01419",
   "metadata": {},
   "source": [
    "# concatenating with Otpimizer = Adadlta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aa78cb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 188s 5s/step\n",
      "(2520, 7, 7, 2048)\n",
      "40/40 [==============================] - 440s 11s/step\n",
      "(2520, 7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "#Resnet50 - last layer of features\n",
    "resnet50_x_train_ada = resnet50.preprocess_input(x_train.copy())\n",
    "resnet50_model_ada = resnet50.ResNet50(weights='imagenet', include_top=False)\n",
    "resnet50_features_ada = resnet50_model_ada.predict(resnet50_x_train_ada, batch_size=64, verbose=1)\n",
    "print(resnet50_features_ada.shape)\n",
    "\n",
    "#vgg16\n",
    "vgg16_x_train_ada = vgg16.preprocess_input(x_train.copy())\n",
    "vgg16_model_ada = vgg16.VGG16(weights='imagenet', include_top=False)\n",
    "vgg16_features_ada = vgg16_model_ada.predict(vgg16_x_train_ada, batch_size=64, verbose=1)\n",
    "print(vgg16_features_ada.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "718398bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2520, 7, 7, 2560)\n"
     ]
    }
   ],
   "source": [
    "concat_ada = np.concatenate([resnet50_features_ada, vgg16_features_ada],axis=3)\n",
    "print(concat_ada.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b716d4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2560)\n",
      "(None, 7)\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape = (7, 7, 2560)) # to take 7 x 7 x 2048 images\n",
    "x = GlobalAveragePooling2D()(inputs) # to convert to 2048 feagures\n",
    "print(x.shape)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "x = Dense(500)(x) # add a dense layer, but not adding activation so that we can add batch-norm first\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "# Softmax layer to the output classes\n",
    "predictions = Dense(num_classes, activation='softmax')(x) # arg1 is: units = dimensionality of the output space.\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c0cb0bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_16 (InputLayer)       [(None, 7, 7, 2560)]      0         \n",
      "                                                                 \n",
      " global_average_pooling2d_4   (None, 2560)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 2560)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 500)               1280500   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 500)              2000      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 500)               0         \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 7)                 3507      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,286,007\n",
      "Trainable params: 1,285,007\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_rv_ada = Model(inputs=inputs, outputs=predictions) # specify what is network input, and what is network output\n",
    "model_rv_ada.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bd64e56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rv_ada.compile(loss='categorical_crossentropy', optimizer=\"Adadelta\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "90432890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 2s 65ms/step - loss: 2.6187 - accuracy: 0.1478 - val_loss: 2.0745 - val_accuracy: 0.0107\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 1s 54ms/step - loss: 2.5879 - accuracy: 0.1397 - val_loss: 1.8963 - val_accuracy: 0.0214\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 2.5925 - accuracy: 0.1455 - val_loss: 1.8058 - val_accuracy: 0.0679\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 1s 50ms/step - loss: 2.5958 - accuracy: 0.1509 - val_loss: 1.7392 - val_accuracy: 0.1286\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 1s 50ms/step - loss: 2.5564 - accuracy: 0.1442 - val_loss: 1.7035 - val_accuracy: 0.1821\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 1s 49ms/step - loss: 2.5579 - accuracy: 0.1536 - val_loss: 1.6783 - val_accuracy: 0.2536\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 1s 49ms/step - loss: 2.5259 - accuracy: 0.1531 - val_loss: 1.6628 - val_accuracy: 0.3107\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 1s 47ms/step - loss: 2.5428 - accuracy: 0.1616 - val_loss: 1.6553 - val_accuracy: 0.3321\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 1s 47ms/step - loss: 2.5447 - accuracy: 0.1522 - val_loss: 1.6512 - val_accuracy: 0.3429\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 1s 47ms/step - loss: 2.5236 - accuracy: 0.1536 - val_loss: 1.6448 - val_accuracy: 0.3607\n",
      "Epoch 11/30\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 2.5112 - accuracy: 0.1683 - val_loss: 1.6453 - val_accuracy: 0.3643\n",
      "Epoch 12/30\n",
      "18/18 [==============================] - 1s 50ms/step - loss: 2.5264 - accuracy: 0.1692 - val_loss: 1.6441 - val_accuracy: 0.3643\n",
      "Epoch 13/30\n",
      "18/18 [==============================] - 1s 48ms/step - loss: 2.4954 - accuracy: 0.1670 - val_loss: 1.6449 - val_accuracy: 0.3643\n",
      "Epoch 14/30\n",
      "18/18 [==============================] - 1s 50ms/step - loss: 2.5090 - accuracy: 0.1598 - val_loss: 1.6406 - val_accuracy: 0.3857\n",
      "Epoch 15/30\n",
      "18/18 [==============================] - 1s 62ms/step - loss: 2.4440 - accuracy: 0.1679 - val_loss: 1.6409 - val_accuracy: 0.3857\n",
      "Epoch 16/30\n",
      "18/18 [==============================] - 1s 53ms/step - loss: 2.4275 - accuracy: 0.1710 - val_loss: 1.6397 - val_accuracy: 0.3857\n",
      "Epoch 17/30\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 2.4861 - accuracy: 0.1634 - val_loss: 1.6375 - val_accuracy: 0.3929\n",
      "Epoch 18/30\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 2.4347 - accuracy: 0.1679 - val_loss: 1.6338 - val_accuracy: 0.4071\n",
      "Epoch 19/30\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 2.4279 - accuracy: 0.1701 - val_loss: 1.6300 - val_accuracy: 0.4286\n",
      "Epoch 20/30\n",
      "18/18 [==============================] - 1s 50ms/step - loss: 2.4346 - accuracy: 0.1714 - val_loss: 1.6269 - val_accuracy: 0.4286\n",
      "Epoch 21/30\n",
      "18/18 [==============================] - 1s 49ms/step - loss: 2.4434 - accuracy: 0.1737 - val_loss: 1.6239 - val_accuracy: 0.4286\n",
      "Epoch 22/30\n",
      "18/18 [==============================] - 1s 49ms/step - loss: 2.4134 - accuracy: 0.1692 - val_loss: 1.6174 - val_accuracy: 0.4607\n",
      "Epoch 23/30\n",
      "18/18 [==============================] - 1s 62ms/step - loss: 2.3903 - accuracy: 0.1710 - val_loss: 1.6169 - val_accuracy: 0.4607\n",
      "Epoch 24/30\n",
      "18/18 [==============================] - 2s 85ms/step - loss: 2.4356 - accuracy: 0.1732 - val_loss: 1.6165 - val_accuracy: 0.4714\n",
      "Epoch 25/30\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 2.3857 - accuracy: 0.1692 - val_loss: 1.6101 - val_accuracy: 0.4750\n",
      "Epoch 26/30\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 2.3862 - accuracy: 0.1772 - val_loss: 1.6088 - val_accuracy: 0.4821\n",
      "Epoch 27/30\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 2.3733 - accuracy: 0.1844 - val_loss: 1.6039 - val_accuracy: 0.4929\n",
      "Epoch 28/30\n",
      "18/18 [==============================] - 1s 47ms/step - loss: 2.3628 - accuracy: 0.1866 - val_loss: 1.6061 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "18/18 [==============================] - 1s 47ms/step - loss: 2.3257 - accuracy: 0.1871 - val_loss: 1.6073 - val_accuracy: 0.5107\n",
      "Epoch 30/30\n",
      "18/18 [==============================] - 1s 64ms/step - loss: 2.3593 - accuracy: 0.1799 - val_loss: 1.6064 - val_accuracy: 0.5107\n",
      "Epoch 30: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21b535517c0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',  patience=3, verbose=1)\n",
    "# stop if loss does not improve for 3 iterations\n",
    "\n",
    "model_rv_ada.fit(concat_ada[:split_point], y_train[:split_point], batch_size=128, epochs=30, \n",
    "              validation_data=(concat_ada[split_point:], y_train[split_point:]), callbacks=[early_stop], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "13d35d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rv_ada.save('model_rv_ada.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fbafdfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_prediction = []\n",
    "for files in os.listdir('./Data/Test_2'):\n",
    "\n",
    "    if files== 'desktop.ini':\n",
    "        pass\n",
    "    else:    \n",
    "        test_img = get_image(f'./Data/Test_2/{files}')\n",
    "        image_batch = np.expand_dims(test_img, axis=0)\n",
    "        image_batch = np.copy(image_batch)\n",
    "        \n",
    "        image_batch1 = resnet50.preprocess_input(image_batch.copy())\n",
    "        image_batch2 = vgg16.preprocess_input(image_batch.copy())\n",
    "        feature_input1 = resnet50_model_ada.predict(image_batch1)\n",
    "        feature_input2 = vgg16_model_ada.predict(image_batch2)\n",
    "        concat2 = np.concatenate([feature_input1,feature_input2],axis=3)\n",
    "        predictions = model_rv_ada.predict(concat2)\n",
    "        pos = np.argmax(predictions)\n",
    "        Test_prediction.append(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b1e05c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.26071428571428573\n"
     ]
    }
   ],
   "source": [
    "test_acc = (Test_prediction == y_test).mean()\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979a1084",
   "metadata": {},
   "source": [
    "# concatenating with Loss = MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "eded036b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 201s 5s/step\n",
      "(2520, 7, 7, 2048)\n",
      "40/40 [==============================] - 501s 12s/step\n",
      "(2520, 7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "#Resnet50 - last layer of features\n",
    "resnet50_x_train_mse = resnet50.preprocess_input(x_train.copy())\n",
    "resnet50_model_mse = resnet50.ResNet50(weights='imagenet', include_top=False)\n",
    "resnet50_features_mse = resnet50_model_mse.predict(resnet50_x_train_mse, batch_size=64, verbose=1)\n",
    "print(resnet50_features_mse.shape)\n",
    "\n",
    "#vgg16\n",
    "vgg16_x_train_mse = vgg16.preprocess_input(x_train.copy())\n",
    "vgg16_model_mse = vgg16.VGG16(weights='imagenet', include_top=False)\n",
    "vgg16_features_mse = vgg16_model_mse.predict(vgg16_x_train_mse, batch_size=64, verbose=1)\n",
    "print(vgg16_features_mse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3f51174b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2520, 7, 7, 2560)\n"
     ]
    }
   ],
   "source": [
    "concat_mse = np.concatenate([resnet50_features_mse, vgg16_features_mse],axis=3)\n",
    "print(concat_mse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "01d230b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2560)\n",
      "(None, 7)\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape = (7, 7, 2560)) # to take 7 x 7 x 2048 images\n",
    "x = GlobalAveragePooling2D()(inputs) # to convert to 2048 feagures\n",
    "print(x.shape)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "x = Dense(500)(x) # add a dense layer, but not adding activation so that we can add batch-norm first\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "# Softmax layer to the output classes\n",
    "predictions = Dense(num_classes, activation='softmax')(x) # arg1 is: units = dimensionality of the output space.\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "662a5662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_19 (InputLayer)       [(None, 7, 7, 2560)]      0         \n",
      "                                                                 \n",
      " global_average_pooling2d_5   (None, 2560)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 2560)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 500)               1280500   \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 500)              2000      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 500)               0         \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 7)                 3507      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,286,007\n",
      "Trainable params: 1,285,007\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_rv_mse = Model(inputs=inputs, outputs=predictions) # specify what is network input, and what is network output\n",
    "model_rv_mse.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dff2dd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rv_mse.compile(loss='mean_squared_error', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3642334a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 2s 55ms/step - loss: 0.0956 - accuracy: 0.4826 - val_loss: 0.1032 - val_accuracy: 0.5286\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 1s 49ms/step - loss: 0.0519 - accuracy: 0.7339 - val_loss: 0.0055 - val_accuracy: 0.9714\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.0408 - accuracy: 0.8036 - val_loss: 0.0063 - val_accuracy: 0.9536\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 1s 61ms/step - loss: 0.0332 - accuracy: 0.8326 - val_loss: 0.0018 - val_accuracy: 0.9929\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.0291 - accuracy: 0.8567 - val_loss: 0.0014 - val_accuracy: 0.9929\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 1s 46ms/step - loss: 0.0256 - accuracy: 0.8826 - val_loss: 0.0016 - val_accuracy: 0.9929\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0245 - accuracy: 0.8906 - val_loss: 0.0015 - val_accuracy: 0.9929\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.0221 - accuracy: 0.8987 - val_loss: 0.0017 - val_accuracy: 0.9929\n",
      "Epoch 8: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21b5e124820>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',  patience=3, verbose=1)\n",
    "# stop if loss does not improve for 3 iterations\n",
    "\n",
    "model_rv_mse.fit(concat_mse[:split_point], y_train[:split_point], batch_size=128, epochs=30, \n",
    "              validation_data=(concat_mse[split_point:], y_train[split_point:]), callbacks=[early_stop], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2404f192",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rv_mse.save('model_rv_mse.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "07ac9d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_prediction = []\n",
    "for files in os.listdir('./Data/Test_2'):\n",
    "\n",
    "    if files== 'desktop.ini':\n",
    "        pass\n",
    "    else:    \n",
    "        test_img = get_image(f'./Data/Test_2/{files}')\n",
    "        image_batch = np.expand_dims(test_img, axis=0)\n",
    "        image_batch = np.copy(image_batch)\n",
    "        \n",
    "        image_batch1 = resnet50.preprocess_input(image_batch.copy())\n",
    "        image_batch2 = vgg16.preprocess_input(image_batch.copy())\n",
    "        feature_input1 = resnet50_model_mse.predict(image_batch1)\n",
    "        feature_input2 = vgg16_model_mse.predict(image_batch2)\n",
    "        concat2 = np.concatenate([feature_input1,feature_input2],axis=3)\n",
    "        predictions = model_rv_mse.predict(concat2)\n",
    "        pos = np.argmax(predictions)\n",
    "        Test_prediction.append(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0dbbc572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.775\n"
     ]
    }
   ],
   "source": [
    "test_acc = (Test_prediction == y_test).mean()\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f09ff81",
   "metadata": {},
   "source": [
    "# concatenating with Loss = MeanAbsoluteError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7fe4652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 192s 5s/step\n",
      "(2520, 7, 7, 2048)\n",
      "40/40 [==============================] - 450s 11s/step\n",
      "(2520, 7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import inception_v3\n",
    "from tensorflow.keras.applications import vgg16\n",
    "\n",
    "#Resnet50 - last layer of features\n",
    "resnet50_x_train_mae = resnet50.preprocess_input(x_train.copy())\n",
    "resnet50_model_mae = resnet50.ResNet50(weights='imagenet', include_top=False)\n",
    "resnet50_features_mae = resnet50_model_mae.predict(resnet50_x_train_mae, batch_size=64, verbose=1)\n",
    "print(resnet50_features_mae.shape)\n",
    "\n",
    "#vgg16\n",
    "vgg16_x_train_mae = vgg16.preprocess_input(x_train.copy())\n",
    "vgg16_model_mae = vgg16.VGG16(weights='imagenet', include_top=False)\n",
    "vgg16_features_mae = vgg16_model_mae.predict(vgg16_x_train_mae, batch_size=64, verbose=1)\n",
    "print(vgg16_features_mae.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85a23259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2520, 7, 7, 2560)\n"
     ]
    }
   ],
   "source": [
    "concat_mae = np.concatenate([resnet50_features_mae, vgg16_features_mae],axis=3)\n",
    "print(concat_mae.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c3bc7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2560)\n",
      "(None, 7)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout, Activation, BatchNormalization\n",
    "\n",
    "inputs = Input(shape = (7, 7, 2560)) # to take 7 x 7 x 2048 images\n",
    "x = GlobalAveragePooling2D()(inputs) # to convert to 2048 feagures\n",
    "print(x.shape)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "x = Dense(500)(x) # add a dense layer, but not adding activation so that we can add batch-norm first\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "# Softmax layer to the output classes\n",
    "predictions = Dense(num_classes, activation='softmax')(x) # arg1 is: units = dimensionality of the output space.\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6e7d283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 7, 7, 2560)]      0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2560)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2560)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 500)               1280500   \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 500)              2000      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 500)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 3507      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,286,007\n",
      "Trainable params: 1,285,007\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "model_rv_mae = Model(inputs=inputs, outputs=predictions) # specify what is network input, and what is network output\n",
    "model_rv_mae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99c052ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rv_mae.compile(loss='mean_absolute_error', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98c4063b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 3s 69ms/step - loss: 0.1616 - accuracy: 0.4705 - val_loss: 0.2672 - val_accuracy: 0.0500\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 1s 56ms/step - loss: 0.0945 - accuracy: 0.7138 - val_loss: 0.0842 - val_accuracy: 0.7321\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 1s 65ms/step - loss: 0.0749 - accuracy: 0.7674 - val_loss: 0.0179 - val_accuracy: 0.9393\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 1s 65ms/step - loss: 0.0605 - accuracy: 0.8174 - val_loss: 0.0204 - val_accuracy: 0.9286\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 1s 63ms/step - loss: 0.0521 - accuracy: 0.8518 - val_loss: 0.0168 - val_accuracy: 0.9464\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 1s 68ms/step - loss: 0.0462 - accuracy: 0.8705 - val_loss: 0.0133 - val_accuracy: 0.9607\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0432 - accuracy: 0.8777 - val_loss: 0.0059 - val_accuracy: 0.9857\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 1s 56ms/step - loss: 0.0390 - accuracy: 0.8938 - val_loss: 0.0033 - val_accuracy: 0.9929\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0345 - accuracy: 0.9031 - val_loss: 0.0025 - val_accuracy: 0.9929\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0322 - accuracy: 0.9116 - val_loss: 0.0023 - val_accuracy: 0.9929\n",
      "Epoch 11/30\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0310 - accuracy: 0.9134 - val_loss: 0.0022 - val_accuracy: 0.9929\n",
      "Epoch 12/30\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0289 - accuracy: 0.9214 - val_loss: 0.0022 - val_accuracy: 0.9929\n",
      "Epoch 13/30\n",
      "18/18 [==============================] - 1s 61ms/step - loss: 0.0281 - accuracy: 0.9241 - val_loss: 0.0023 - val_accuracy: 0.9929\n",
      "Epoch 14/30\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0275 - accuracy: 0.9210 - val_loss: 0.0024 - val_accuracy: 0.9929\n",
      "Epoch 15/30\n",
      "18/18 [==============================] - 1s 60ms/step - loss: 0.0247 - accuracy: 0.9330 - val_loss: 0.0022 - val_accuracy: 0.9929\n",
      "Epoch 16/30\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0251 - accuracy: 0.9299 - val_loss: 0.0022 - val_accuracy: 0.9929\n",
      "Epoch 17/30\n",
      "18/18 [==============================] - 1s 62ms/step - loss: 0.0208 - accuracy: 0.9460 - val_loss: 0.0024 - val_accuracy: 0.9929\n",
      "Epoch 18/30\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0236 - accuracy: 0.9335 - val_loss: 0.0024 - val_accuracy: 0.9929\n",
      "Epoch 19/30\n",
      "18/18 [==============================] - 1s 49ms/step - loss: 0.0221 - accuracy: 0.9330 - val_loss: 0.0024 - val_accuracy: 0.9929\n",
      "Epoch 19: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bb802d5850>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss',  patience=3, verbose=1)\n",
    "# stop if loss does not improve for 3 iterations\n",
    "\n",
    "model_rv_mae.fit(concat_mae[:split_point], y_train[:split_point], batch_size=128, epochs=30, \n",
    "              validation_data=(concat_mae[split_point:], y_train[split_point:]), callbacks=[early_stop], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0923841a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rv_mae.save('model_rv_mae.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1fd0373",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_prediction = []\n",
    "for files in os.listdir('./Data/Test_2'):\n",
    "\n",
    "    if files== 'desktop.ini':\n",
    "        pass\n",
    "    else:    \n",
    "        test_img = get_image(f'./Data/Test_2/{files}')\n",
    "        image_batch = np.expand_dims(test_img, axis=0)\n",
    "        image_batch = np.copy(image_batch)\n",
    "        \n",
    "        image_batch1 = resnet50.preprocess_input(image_batch.copy())\n",
    "        image_batch2 = vgg16.preprocess_input(image_batch.copy())\n",
    "        feature_input1 = resnet50_model_mae.predict(image_batch1)\n",
    "        feature_input2 = vgg16_model_mae.predict(image_batch2)\n",
    "        concat2 = np.concatenate([feature_input1,feature_input2],axis=3)\n",
    "        predictions = model_rv_mae.predict(concat2)\n",
    "        pos = np.argmax(predictions)\n",
    "        Test_prediction.append(pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "631c3bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.8\n"
     ]
    }
   ],
   "source": [
    "y_test = pd.read_excel(r'./Data/test_2_label.xlsx',usecols=[1,1])\n",
    "y_test = y_test.to_numpy()\n",
    "y_test = np.squeeze(y_test)\n",
    "test_acc = (Test_prediction == y_test).mean()\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ffba47",
   "metadata": {},
   "source": [
    "# concatenating with Loss = Hinge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "155e287a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 193s 5s/step\n",
      "(2520, 7, 7, 2048)\n",
      "40/40 [==============================] - 476s 12s/step\n",
      "(2520, 7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "#Resnet50 - last layer of features\n",
    "resnet50_x_train_hinge = resnet50.preprocess_input(x_train.copy())\n",
    "resnet50_model_hinge = resnet50.ResNet50(weights='imagenet', include_top=False)\n",
    "resnet50_features_hinge = resnet50_model_hinge.predict(resnet50_x_train_hinge, batch_size=64, verbose=1)\n",
    "print(resnet50_features_hinge.shape)\n",
    "\n",
    "#vgg16\n",
    "vgg16_x_train_hinge = vgg16.preprocess_input(x_train.copy())\n",
    "vgg16_model_hinge = vgg16.VGG16(weights='imagenet', include_top=False)\n",
    "vgg16_features_hinge = vgg16_model_hinge.predict(vgg16_x_train_hinge, batch_size=64, verbose=1)\n",
    "print(vgg16_features_hinge.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03029030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2520, 7, 7, 2560)\n"
     ]
    }
   ],
   "source": [
    "concat_hinge = np.concatenate([resnet50_features_hinge, vgg16_features_hinge],axis=3)\n",
    "print(concat_hinge.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e08195e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2560)\n",
      "(None, 7)\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape = (7, 7, 2560)) # to take 7 x 7 x 2048 images\n",
    "x = GlobalAveragePooling2D()(inputs) # to convert to 2048 feagures\n",
    "print(x.shape)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "x = Dense(500)(x) # add a dense layer, but not adding activation so that we can add batch-norm first\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "# Softmax layer to the output classes\n",
    "predictions = Dense(num_classes, activation='softmax')(x) # arg1 is: units = dimensionality of the output space.\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bc5b72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 7, 7, 2560)]      0         \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 2560)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 2560)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 500)               1280500   \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 500)              2000      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 500)               0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 7)                 3507      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,286,007\n",
      "Trainable params: 1,285,007\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_rv_hinge = Model(inputs=inputs, outputs=predictions) # specify what is network input, and what is network output\n",
    "model_rv_hinge.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18e8513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rv_hinge.compile(loss='hinge', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93510011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 2s 91ms/step - loss: 1.0251 - accuracy: 0.4375 - val_loss: 1.1260 - val_accuracy: 0.0250\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 1s 47ms/step - loss: 0.9561 - accuracy: 0.6996 - val_loss: 0.9784 - val_accuracy: 0.5893\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.9310 - accuracy: 0.7772 - val_loss: 0.9035 - val_accuracy: 0.8250\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.9147 - accuracy: 0.8411 - val_loss: 0.8774 - val_accuracy: 0.9250\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.9095 - accuracy: 0.8473 - val_loss: 0.8699 - val_accuracy: 0.9607\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 1s 46ms/step - loss: 0.9027 - accuracy: 0.8674 - val_loss: 0.8669 - val_accuracy: 0.9643\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.8969 - accuracy: 0.8938 - val_loss: 0.8627 - val_accuracy: 0.9857\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.8947 - accuracy: 0.8915 - val_loss: 0.8603 - val_accuracy: 0.9929\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 1s 47ms/step - loss: 0.8907 - accuracy: 0.9071 - val_loss: 0.8597 - val_accuracy: 0.9929\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 1s 46ms/step - loss: 0.8904 - accuracy: 0.9107 - val_loss: 0.8600 - val_accuracy: 0.9929\n",
      "Epoch 11/30\n",
      "18/18 [==============================] - 1s 61ms/step - loss: 0.8878 - accuracy: 0.9103 - val_loss: 0.8603 - val_accuracy: 0.9893\n",
      "Epoch 12/30\n",
      "18/18 [==============================] - 1s 46ms/step - loss: 0.8862 - accuracy: 0.9161 - val_loss: 0.8596 - val_accuracy: 0.9929\n",
      "Epoch 13/30\n",
      "18/18 [==============================] - 1s 54ms/step - loss: 0.8832 - accuracy: 0.9304 - val_loss: 0.8596 - val_accuracy: 0.9929\n",
      "Epoch 14/30\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.8828 - accuracy: 0.9263 - val_loss: 0.8602 - val_accuracy: 0.9893\n",
      "Epoch 15/30\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.8799 - accuracy: 0.9339 - val_loss: 0.8606 - val_accuracy: 0.9893\n",
      "Epoch 16/30\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.8798 - accuracy: 0.9366 - val_loss: 0.8604 - val_accuracy: 0.9893\n",
      "Epoch 16: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bb85546a30>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',  patience=3, verbose=1)\n",
    "# stop if loss does not improve for 3 iterations\n",
    "\n",
    "model_rv_hinge.fit(concat_hinge[:split_point], y_train[:split_point], batch_size=128, epochs=30, \n",
    "              validation_data=(concat_hinge[split_point:], y_train[split_point:]), callbacks=[early_stop], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62120f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rv_hinge.save('model_rv_hinge.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98890e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_prediction = []\n",
    "for files in os.listdir('./Data/Test_2'):\n",
    "\n",
    "    if files== 'desktop.ini':\n",
    "        pass\n",
    "    else:    \n",
    "        test_img = get_image(f'./Data/Test_2/{files}')\n",
    "        image_batch = np.expand_dims(test_img, axis=0)\n",
    "        image_batch = np.copy(image_batch)\n",
    "        \n",
    "        image_batch1 = resnet50.preprocess_input(image_batch.copy())\n",
    "        image_batch2 = vgg16.preprocess_input(image_batch.copy())\n",
    "        feature_input1 = resnet50_model_hinge.predict(image_batch1)\n",
    "        feature_input2 = vgg16_model_hinge.predict(image_batch2)\n",
    "        concat2 = np.concatenate([feature_input1,feature_input2],axis=3)\n",
    "        predictions = model_rv_hinge.predict(concat2)\n",
    "        pos = np.argmax(predictions)\n",
    "        Test_prediction.append(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28488b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.7785714285714286\n"
     ]
    }
   ],
   "source": [
    "test_acc = (Test_prediction == y_test).mean()\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89733b56",
   "metadata": {},
   "source": [
    "# concatenating with Loss = SquaredHinge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d19531c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 189s 5s/step\n",
      "(2520, 7, 7, 2048)\n",
      "40/40 [==============================] - 485s 12s/step\n",
      "(2520, 7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "#Resnet50 - last layer of features\n",
    "resnet50_x_train_sh = resnet50.preprocess_input(x_train.copy())\n",
    "resnet50_model_sh = resnet50.ResNet50(weights='imagenet', include_top=False)\n",
    "resnet50_features_sh = resnet50_model_sh.predict(resnet50_x_train_sh, batch_size=64, verbose=1)\n",
    "print(resnet50_features_sh.shape)\n",
    "\n",
    "#vgg16\n",
    "vgg16_x_train_sh = vgg16.preprocess_input(x_train.copy())\n",
    "vgg16_model_sh = vgg16.VGG16(weights='imagenet', include_top=False)\n",
    "vgg16_features_sh = vgg16_model_sh.predict(vgg16_x_train_sh, batch_size=64, verbose=1)\n",
    "print(vgg16_features_sh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce33bee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2520, 7, 7, 2560)\n"
     ]
    }
   ],
   "source": [
    "concat_sh = np.concatenate([resnet50_features_sh, vgg16_features_sh],axis=3)\n",
    "print(concat_sh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2946f786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2560)\n",
      "(None, 7)\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape = (7, 7, 2560)) # to take 7 x 7 x 2048 images\n",
    "x = GlobalAveragePooling2D()(inputs) # to convert to 2048 feagures\n",
    "print(x.shape)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "x = Dense(500)(x) # add a dense layer, but not adding activation so that we can add batch-norm first\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "# Softmax layer to the output classes\n",
    "predictions = Dense(num_classes, activation='softmax')(x) # arg1 is: units = dimensionality of the output space.\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "900fa976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 7, 7, 2560)]      0         \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 2560)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 2560)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 500)               1280500   \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 500)              2000      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 500)               0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 7)                 3507      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,286,007\n",
      "Trainable params: 1,285,007\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_rv_sh = Model(inputs=inputs, outputs=predictions) # specify what is network input, and what is network output\n",
    "model_rv_sh.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07b2961a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rv_sh.compile(loss='squared_hinge', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e45a7741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 2s 58ms/step - loss: 1.1189 - accuracy: 0.4795 - val_loss: 1.0997 - val_accuracy: 0.5429\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 1.0053 - accuracy: 0.7272 - val_loss: 0.9344 - val_accuracy: 0.8321\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.9708 - accuracy: 0.8040 - val_loss: 0.8840 - val_accuracy: 0.9607\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.9501 - accuracy: 0.8402 - val_loss: 0.8820 - val_accuracy: 0.9643\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 1s 46ms/step - loss: 0.9361 - accuracy: 0.8728 - val_loss: 0.8644 - val_accuracy: 0.9929\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.9293 - accuracy: 0.8804 - val_loss: 0.8660 - val_accuracy: 0.9929\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 1s 46ms/step - loss: 0.9201 - accuracy: 0.9027 - val_loss: 0.8618 - val_accuracy: 0.9929\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 1s 56ms/step - loss: 0.9177 - accuracy: 0.8987 - val_loss: 0.8617 - val_accuracy: 0.9929\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 1s 49ms/step - loss: 0.9136 - accuracy: 0.9031 - val_loss: 0.8621 - val_accuracy: 0.9929\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 1s 48ms/step - loss: 0.9109 - accuracy: 0.9143 - val_loss: 0.8623 - val_accuracy: 0.9929\n",
      "Epoch 11/30\n",
      "18/18 [==============================] - 1s 67ms/step - loss: 0.9061 - accuracy: 0.9183 - val_loss: 0.8626 - val_accuracy: 0.9929\n",
      "Epoch 11: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bb8f9d8e20>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',  patience=3, verbose=1)\n",
    "# stop if loss does not improve for 3 iterations\n",
    "\n",
    "model_rv_sh.fit(concat_sh[:split_point], y_train[:split_point], batch_size=128, epochs=30, \n",
    "              validation_data=(concat_sh[split_point:], y_train[split_point:]), callbacks=[early_stop], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0abb99f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rv_sh.save('model_rv_sh.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a75e5ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_prediction = []\n",
    "for files in os.listdir('./Data/Test_2'):\n",
    "\n",
    "    if files== 'desktop.ini':\n",
    "        pass\n",
    "    else:    \n",
    "        test_img = get_image(f'./Data/Test_2/{files}')\n",
    "        image_batch = np.expand_dims(test_img, axis=0)\n",
    "        image_batch = np.copy(image_batch)\n",
    "        \n",
    "        image_batch1 = resnet50.preprocess_input(image_batch.copy())\n",
    "        image_batch2 = vgg16.preprocess_input(image_batch.copy())\n",
    "        feature_input1 = resnet50_model_sh.predict(image_batch1)\n",
    "        feature_input2 = vgg16_model_sh.predict(image_batch2)\n",
    "        concat2 = np.concatenate([feature_input1,feature_input2],axis=3)\n",
    "        predictions = model_rv_sh.predict(concat2)\n",
    "        pos = np.argmax(predictions)\n",
    "        Test_prediction.append(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a974ca09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.7678571428571429\n"
     ]
    }
   ],
   "source": [
    "test_acc = (Test_prediction == y_test).mean()\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14316117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d9ad24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ea4a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
