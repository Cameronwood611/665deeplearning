{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98c24bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.applications import resnet50\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c0d35d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_train_images: 2520\n",
      "Types: Index(['distribute', 'ineq', 'integral', 'limit', 'matrix', 'series', 'sqrt'], dtype='object')\n",
      "num_classes: 7\n"
     ]
    }
   ],
   "source": [
    "labels = pd.read_csv('Data/train_label.csv')\n",
    "sample = pd.read_csv('Data/sample_submission.csv')\n",
    "# num_train_images = labels.shape[0]\n",
    "num_train_images = 2520  # we choose 3300 images for this assignment. It works for a machine having 8Gb Ram. You can adjust it if your Ram is different. \n",
    "split_point = 2240 # split the data into training data [0:3000] and val data [3000:]\n",
    "print('num_train_images:', num_train_images)\n",
    "types = sample.columns[1:]\n",
    "print('Types:', types)\n",
    "num_classes = len(types)\n",
    "print('num_classes:', num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dee14213",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "\n",
    "img_width = 224\n",
    "\n",
    "def get_image(filename):\n",
    "    ########################################################################\n",
    "    # TODO: Your code here...\n",
    "    ########################################################################\n",
    "    original = load_img(filename, target_size=(224,224))\n",
    "    numpy_image = img_to_array(original)\n",
    "    image_batch = np.expand_dims(numpy_image, axis=0)\n",
    "    return image_batch[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad8fc5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 images loaded\n",
      "2000 images loaded\n"
     ]
    }
   ],
   "source": [
    "x_train = np.zeros((num_train_images, img_width, img_width, 3), dtype=np.uint8)\n",
    "y_train = np.zeros((num_train_images, num_classes), dtype=np.uint8)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for i in range(num_train_images):\n",
    "    x_train[i] = get_image('Data/train/%s.png' % labels['id'][i])\n",
    "    pos_arrays = (types == labels['Type'][i]).nonzero() # recall that types is the array of classes\n",
    "    pos = pos_arrays[0][0]\n",
    "    y_train[i][pos] = 1\n",
    "    count += 1\n",
    "    if(count % 1000 == 0): print(count, 'images loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d64ef58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 195s 5s/step\n",
      "(2520, 7, 7, 2048)\n",
      "40/40 [==============================] - 483s 12s/step\n",
      "(2520, 7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import inception_v3\n",
    "from tensorflow.keras.applications import vgg16\n",
    "\n",
    "#getting the features of all three models\n",
    "\n",
    "#Resnet50 - last layer of features\n",
    "resnet50_x_train = resnet50.preprocess_input(x_train.copy())\n",
    "resnet50_model = resnet50.ResNet50(weights='imagenet', include_top=False)\n",
    "resnet50_features = resnet50_model.predict(resnet50_x_train, batch_size=64, verbose=1)\n",
    "print(resnet50_features.shape)\n",
    "\n",
    "#vgg16\n",
    "vgg16_x_train = vgg16.preprocess_input(x_train.copy())\n",
    "vgg16_model = vgg16.VGG16(weights='imagenet', include_top=False)\n",
    "vgg16_features = vgg16_model.predict(vgg16_x_train, batch_size=64, verbose=1)\n",
    "print(vgg16_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d13235c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2520, 7, 7, 2560)\n"
     ]
    }
   ],
   "source": [
    "concat = np.concatenate([resnet50_features, vgg16_features],axis=3)\n",
    "print(concat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "000b1382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2560)\n",
      "(None, 7)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout, Activation, BatchNormalization\n",
    "\n",
    "inputs = Input(shape = (7, 7, 2560)) # to take 7 x 7 x 2048 images\n",
    "x = GlobalAveragePooling2D()(inputs) # to convert to 2048 feagures\n",
    "print(x.shape)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "x = Dense(500)(x) # add a dense layer, but not adding activation so that we can add batch-norm first\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "# Softmax layer to the output classes\n",
    "predictions = Dense(num_classes, activation='softmax')(x) # arg1 is: units = dimensionality of the output space.\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ed42bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"./models/model_rv_mae.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0d48db",
   "metadata": {},
   "source": [
    "## do NOT run this cell if you did not collect you own data. This cell processes the pictures for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fae69b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def make_bitmap(img: np.ndarray):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    filter = cv2.getGaussianKernel(31, 11)\n",
    "    filter = filter * filter.T\n",
    "    smoothed_im = cv2.filter2D(img, 0, filter)\n",
    "    _, img = cv2.threshold(smoothed_im, 115, 255, cv2.THRESH_BINARY)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    return img\n",
    "\n",
    "\n",
    "def resize_img(im: np.ndarray, dim: tuple):\n",
    "    y, x = im.shape[0], im.shape[1]\n",
    "    y_out, x_out = dim\n",
    "\n",
    "    if y_out > y:\n",
    "        diff = abs(y_out - y)\n",
    "        padding = math.ceil(diff / 2)\n",
    "        im = cv2.copyMakeBorder(im, padding, padding, 0, 0, cv2.BORDER_CONSTANT, None, value=[255, 255, 255])\n",
    "\n",
    "    if x_out > x:\n",
    "        diff = abs(y_out - y)\n",
    "        padding = math.ceil(diff / 2)\n",
    "        im = cv2.copyMakeBorder(im, 0, 0, padding, padding, cv2.BORDER_CONSTANT, None, value=[255, 255, 255])\n",
    "    \n",
    "    im = cv2.resize(im, dim, interpolation= cv2.INTER_CUBIC)\n",
    "    return im\n",
    "\n",
    "\n",
    "def display(im):\n",
    "    cv2.imshow(\"Image\", im)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "def write_from_dir(read_path: str):\n",
    "    for file in os.listdir(read_path):\n",
    "        if os.path.isfile(os.path.join(read_path, file)):\n",
    "            sub_dir = read_path.split(\"/\")[-1]\n",
    "            new_dir = \"./data/\" + sub_dir\n",
    "            old_filepath = os.path.join(read_path, file)\n",
    "            new_filepath = os.path.join(new_dir, file)\n",
    "            os.makedirs(new_dir, exist_ok=True)\n",
    "            img = cv2.imread(old_filepath)\n",
    "            if img is not None:\n",
    "                try:\n",
    "                    img = resize_img(img, (250, 250))\n",
    "                except:\n",
    "                    print(old_filepath)\n",
    "                cv2.imwrite(new_filepath, img)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dirs = [\n",
    "    \"./Data/Test_8\",\n",
    "\n",
    "]\n",
    "for dir in dirs:\n",
    "    write_from_dir(dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea23e50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_prediction = []\n",
    "for files in os.listdir('./Data/Test_e'):\n",
    "\n",
    "    if files== 'desktop.ini':\n",
    "        pass\n",
    "    else:    \n",
    "        test_img = get_image(f'./Data/Test_e/{files}')\n",
    "        image_batch = np.expand_dims(test_img, axis=0)\n",
    "        image_batch = np.copy(image_batch)\n",
    "        \n",
    "        image_batch1 = resnet50.preprocess_input(image_batch.copy())\n",
    "        image_batch2 = vgg16.preprocess_input(image_batch.copy())\n",
    "        feature_input1 = resnet50_model.predict(image_batch1)\n",
    "        feature_input2 = vgg16_model.predict(image_batch2)\n",
    "        concat2 = np.concatenate([feature_input1,feature_input2],axis=3)\n",
    "        predictions = model.predict(concat2)\n",
    "        pos = np.argmax(predictions)\n",
    "        Test_prediction.append(pos)\n",
    "\n",
    "        #print('Image Name: ',files,' Prediction: ',types[pos])\n",
    "#Test_prediction\n",
    "#Test_prediction = np.array(Test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd30e495",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test_prediction = np.array(Test_prediction)\n",
    "y_test = pd.read_excel(r'./Data/test_e_label.xlsx',usecols=[1,1])\n",
    "y_test = y_test.to_numpy()\n",
    "y_test = np.squeeze(y_test)\n",
    "# print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b7a08eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.6\n"
     ]
    }
   ],
   "source": [
    "test_acc = (Test_prediction == y_test).mean()\n",
    "\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87f002b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Name:  cam dist.png  Prediction:  ineq\n",
      "Image Name:  cam ineq.png  Prediction:  ineq\n",
      "Image Name:  cam int.png  Prediction:  integral\n",
      "Image Name:  cam limit.png  Prediction:  limit\n",
      "Image Name:  cam mat.png  Prediction:  integral\n",
      "Image Name:  cam series.png  Prediction:  series\n",
      "Image Name:  cam sqrt.png  Prediction:  sqrt\n"
     ]
    }
   ],
   "source": [
    "for files in os.listdir('./Data/Test_Cam/'):\n",
    "    \n",
    "    if files== 'desktop.ini':\n",
    "        pass\n",
    "    else:    \n",
    "        test_img = get_image(f'./Data/Test_Cam/{files}')\n",
    "        image_batch = np.expand_dims(test_img, axis=0)\n",
    "        image_batch = np.copy(image_batch)\n",
    "        \n",
    "        image_batch1 = resnet50.preprocess_input(image_batch.copy())\n",
    "        image_batch2 = vgg16.preprocess_input(image_batch.copy())\n",
    "        feature_input1 = resnet50_model.predict(image_batch1)\n",
    "        feature_input2 = vgg16_model.predict(image_batch2)\n",
    "        concat2 = np.concatenate([feature_input1,feature_input2],axis=3)\n",
    "        predictions = model.predict(concat2)\n",
    "        pos = np.argmax(predictions)\n",
    "        Test_prediction.append(pos)\n",
    "\n",
    "        print('Image Name: ',files,' Prediction: ',types[pos])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dd1c30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
