{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b598b15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.applications import resnet50\n",
    "from keras_applications import resnext\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddcdfd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_train_images: 2520\n",
      "Types: Index(['distribute', 'ineq', 'integral', 'limit', 'matrix', 'series', 'sqrt'], dtype='object')\n",
      "num_classes: 7\n"
     ]
    }
   ],
   "source": [
    "labels = pd.read_csv('Data/train_label.csv')\n",
    "labels['Type'].value_counts()\n",
    "sample = pd.read_csv('Data/sample_submission.csv')\n",
    "num_train_images = 2520  # we choose 3300 images for this assignment. It works for a machine having 8Gb Ram. You can adjust it if your Ram is different. \n",
    "split_point = 2240 # split the data into training data [0:3000] and val data [3000:]\n",
    "print('num_train_images:', num_train_images)\n",
    "types = sample.columns[1:]\n",
    "print('Types:', types)\n",
    "num_classes = len(types)\n",
    "print('num_classes:', num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb5b3caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "\n",
    "img_width = 224\n",
    "\n",
    "def get_image(filename):\n",
    "    ########################################################################\n",
    "    # TODO: Your code here...\n",
    "    ########################################################################\n",
    "    original = load_img(filename, target_size=(224,224))\n",
    "    numpy_image = img_to_array(original)\n",
    "    image_batch = np.expand_dims(numpy_image, axis=0)\n",
    "    return image_batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "561cb5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 images loaded\n",
      "2000 images loaded\n"
     ]
    }
   ],
   "source": [
    "x_train = np.zeros((num_train_images, img_width, img_width, 3), dtype=np.uint8)\n",
    "y_train = np.zeros((num_train_images, num_classes), dtype=np.uint8)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for i in range(num_train_images):\n",
    "    x_train[i] = get_image('Data/train/%s.png' % labels['id'][i])\n",
    "    pos_arrays = (types == labels['Type'][i]).nonzero() # recall that types is the array of classes\n",
    "    pos = pos_arrays[0][0]\n",
    "    y_train[i][pos] = 1\n",
    "    count += 1\n",
    "    if(count % 1000 == 0): print(count, 'images loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eedbf45",
   "metadata": {},
   "source": [
    "# Inception with nothing changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc9d949f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 98s 2s/step\n",
      "(2520, 5, 5, 2048)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import inception_v3\n",
    "inception_x_train = inception_v3.preprocess_input(x_train.copy())\n",
    "inception_model = inception_v3.InceptionV3(weights='imagenet', include_top=False)\n",
    "inception_features = inception_model.predict(inception_x_train, batch_size=64, verbose=1)\n",
    "print(inception_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "835c4687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2048)\n",
      "(None, 7)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout, Activation, BatchNormalization\n",
    "\n",
    "inputs = Input(shape = (5, 5, 2048)) # to take 7 x 7 x 2048 images\n",
    "x = GlobalAveragePooling2D()(inputs) # to convert to 2048 feagures\n",
    "print(x.shape)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "x = Dense(500)(x) # add a dense layer, but not adding activation so that we can add batch-norm first\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "# Softmax layer to the output classes\n",
    "predictions = Dense(num_classes, activation='softmax')(x) # arg1 is: units = dimensionality of the output space.\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40d40014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 5, 5, 2048)]      0         \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 500)               1024500   \n",
      "                                                                 \n",
      " batch_normalization_95 (Bat  (None, 500)              2000      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_95 (Activation)  (None, 500)               0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 7)                 3507      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,030,007\n",
      "Trainable params: 1,029,007\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "model_i = Model(inputs=inputs, outputs=predictions) # specify what is network input, and what is network output\n",
    "model_i.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4cece05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_i.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0894dc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 1.3024 - accuracy: 0.5482 - val_loss: 0.4914 - val_accuracy: 0.8536\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.6688 - accuracy: 0.7683 - val_loss: 0.1785 - val_accuracy: 0.9643\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.5328 - accuracy: 0.8138 - val_loss: 0.2078 - val_accuracy: 0.9429\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.4450 - accuracy: 0.8554 - val_loss: 0.2223 - val_accuracy: 0.9393\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4039 - accuracy: 0.8638 - val_loss: 0.1862 - val_accuracy: 0.9500\n",
      "Epoch 5: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x294434949d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss',  patience=3, verbose=1)\n",
    "# stop if loss does not improve for 3 iterations\n",
    "\n",
    "model_i.fit(inception_features[:split_point], y_train[:split_point], batch_size=128, epochs=30, \n",
    "              validation_data=(inception_features[split_point:], y_train[split_point:]), callbacks=[early_stop], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef692a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_i.save('model_i.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "508e3e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_prediction = []\n",
    "for files in os.listdir('./Data/Test_2'):\n",
    "\n",
    "    if files== 'desktop.ini':\n",
    "        pass\n",
    "    else:    \n",
    "        test_img = get_image(f'./Data/Test_2/{files}')\n",
    "        image_batch = np.expand_dims(test_img, axis=0)\n",
    "        image_batch = np.copy(image_batch)\n",
    "        image_batch = inception_v3.preprocess_input(image_batch)\n",
    "        feature_input = inception_model.predict(image_batch)\n",
    "        predictions = model_i.predict(feature_input)\n",
    "        pos = np.argmax(predictions)\n",
    "        Test_prediction.append(pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e96ea036",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.read_excel(r'./Data/test_2_label.xlsx',usecols=[1,1])\n",
    "y_test = y_test.to_numpy()\n",
    "y_test = np.squeeze(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c66a230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.725\n"
     ]
    }
   ],
   "source": [
    "test_acc = (Test_prediction == y_test).mean()\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a065b6e",
   "metadata": {},
   "source": [
    "# Inception with Activation = Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5389724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 105s 3s/step\n",
      "(2520, 5, 5, 2048)\n"
     ]
    }
   ],
   "source": [
    "inception_x_train_sig = inception_v3.preprocess_input(x_train.copy())\n",
    "inception_model_sig = inception_v3.InceptionV3(weights='imagenet', include_top=False)\n",
    "inception_features_sig = inception_model_sig.predict(inception_x_train_sig, batch_size=64, verbose=1)\n",
    "print(inception_features_sig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3121e479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2048)\n",
      "(None, 7)\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape = (5, 5, 2048)) # to take 7 x 7 x 2048 images\n",
    "x = GlobalAveragePooling2D()(inputs) # to convert to 2048 feagures\n",
    "print(x.shape)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "x = Dense(500)(x) # add a dense layer, but not adding activation so that we can add batch-norm first\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"sigmoid\")(x)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "# Softmax layer to the output classes\n",
    "predictions = Dense(num_classes, activation='softmax')(x) # arg1 is: units = dimensionality of the output space.\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "187728ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 5, 5, 2048)]      0         \n",
      "                                                                 \n",
      " global_average_pooling2d_4   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 500)               1024500   \n",
      "                                                                 \n",
      " batch_normalization_192 (Ba  (None, 500)              2000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_192 (Activation)  (None, 500)              0         \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 7)                 3507      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,030,007\n",
      "Trainable params: 1,029,007\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_i_sig = Model(inputs=inputs, outputs=predictions) # specify what is network input, and what is network output\n",
    "model_i_sig.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9fbf69f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_i_sig.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dcb39d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 1.3383 - accuracy: 0.5045 - val_loss: 1.0109 - val_accuracy: 0.6536\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.8113 - accuracy: 0.7129 - val_loss: 0.7366 - val_accuracy: 0.7500\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.6703 - accuracy: 0.7790 - val_loss: 0.3748 - val_accuracy: 0.9286\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.5890 - accuracy: 0.8049 - val_loss: 0.4157 - val_accuracy: 0.9000\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.5538 - accuracy: 0.8112 - val_loss: 0.3194 - val_accuracy: 0.9357\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.5074 - accuracy: 0.8272 - val_loss: 0.3156 - val_accuracy: 0.9393\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4757 - accuracy: 0.8402 - val_loss: 0.2320 - val_accuracy: 0.9500\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4419 - accuracy: 0.8558 - val_loss: 0.2221 - val_accuracy: 0.9536\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4313 - accuracy: 0.8589 - val_loss: 0.1961 - val_accuracy: 0.9429\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.3919 - accuracy: 0.8696 - val_loss: 0.2292 - val_accuracy: 0.9214\n",
      "Epoch 11/30\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.4007 - accuracy: 0.8634 - val_loss: 0.1849 - val_accuracy: 0.9536\n",
      "Epoch 12/30\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.3853 - accuracy: 0.8696 - val_loss: 0.1513 - val_accuracy: 0.9679\n",
      "Epoch 13/30\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.3711 - accuracy: 0.8768 - val_loss: 0.1820 - val_accuracy: 0.9464\n",
      "Epoch 14/30\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.3529 - accuracy: 0.8830 - val_loss: 0.1891 - val_accuracy: 0.9429\n",
      "Epoch 15/30\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.3373 - accuracy: 0.8888 - val_loss: 0.1541 - val_accuracy: 0.9714\n",
      "Epoch 15: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29443d06d30>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',  patience=3, verbose=1)\n",
    "# stop if loss does not improve for 3 iterations\n",
    "\n",
    "model_i_sig.fit(inception_features_sig[:split_point], y_train[:split_point], batch_size=128, epochs=30, \n",
    "              validation_data=(inception_features_sig[split_point:], y_train[split_point:]), callbacks=[early_stop], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7f8e172",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_i_sig.save('model_i_sig.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77496f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_prediction = []\n",
    "for files in os.listdir('./Data/Test_2'):\n",
    "\n",
    "    if files== 'desktop.ini':\n",
    "        pass\n",
    "    else:    \n",
    "        test_img = get_image(f'./Data/Test_2/{files}')\n",
    "        image_batch = np.expand_dims(test_img, axis=0)\n",
    "        image_batch = np.copy(image_batch)\n",
    "        image_batch = inception_v3.preprocess_input(image_batch)\n",
    "        feature_input = inception_model_sig.predict(image_batch)\n",
    "        predictions = model_i_sig.predict(feature_input)\n",
    "        pos = np.argmax(predictions)\n",
    "        Test_prediction.append(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c78888f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.7928571428571428\n"
     ]
    }
   ],
   "source": [
    "test_acc = (Test_prediction == y_test).mean()\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6c7611",
   "metadata": {},
   "source": [
    "# Inception with Activation = Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82e08b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 106s 3s/step\n",
      "(2520, 5, 5, 2048)\n"
     ]
    }
   ],
   "source": [
    "inception_x_train_tanh = inception_v3.preprocess_input(x_train.copy())\n",
    "inception_model_tanh = inception_v3.InceptionV3(weights='imagenet', include_top=False)\n",
    "inception_features_tanh = inception_model_tanh.predict(inception_x_train_tanh, batch_size=64, verbose=1)\n",
    "print(inception_features_tanh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20a8a245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2048)\n",
      "(None, 7)\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape = (5, 5, 2048)) # to take 7 x 7 x 2048 images\n",
    "x = GlobalAveragePooling2D()(inputs) # to convert to 2048 feagures\n",
    "print(x.shape)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "x = Dense(500)(x) # add a dense layer, but not adding activation so that we can add batch-norm first\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"tanh\")(x)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "# Softmax layer to the output classes\n",
    "predictions = Dense(num_classes, activation='softmax')(x) # arg1 is: units = dimensionality of the output space.\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bdc3007c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 5, 5, 2048)]      0         \n",
      "                                                                 \n",
      " global_average_pooling2d_7   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 500)               1024500   \n",
      "                                                                 \n",
      " batch_normalization_383 (Ba  (None, 500)              2000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_383 (Activation)  (None, 500)              0         \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 7)                 3507      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,030,007\n",
      "Trainable params: 1,029,007\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_i_tanh = Model(inputs=inputs, outputs=predictions) # specify what is network input, and what is network output\n",
    "model_i_tanh.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "090f0f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_i_tanh.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d90a9773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 1.9322 - accuracy: 0.4705 - val_loss: 1.9651 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 1.9118 - accuracy: 0.6460 - val_loss: 1.9878 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 1.8960 - accuracy: 0.7031 - val_loss: 2.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 1.8801 - accuracy: 0.7469 - val_loss: 2.0319 - val_accuracy: 0.0000e+00\n",
      "Epoch 4: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29465caff70>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',  patience=3, verbose=1)\n",
    "# stop if loss does not improve for 3 iterations\n",
    "\n",
    "model_i_tanh.fit(inception_features_tanh[:split_point], y_train[:split_point], batch_size=128, epochs=30, \n",
    "              validation_data=(inception_features_tanh[split_point:], y_train[split_point:]), callbacks=[early_stop], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1af1637b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_i_tanh.save('model_i_tanh.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "070835e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_prediction = []\n",
    "for files in os.listdir('./Data/Test_2'):\n",
    "\n",
    "    if files== 'desktop.ini':\n",
    "        pass\n",
    "    else:    \n",
    "        test_img = get_image(f'./Data/Test_2/{files}')\n",
    "        image_batch = np.expand_dims(test_img, axis=0)\n",
    "        image_batch = np.copy(image_batch)\n",
    "        image_batch = inception_v3.preprocess_input(image_batch)\n",
    "        feature_input = inception_model_tanh.predict(image_batch)\n",
    "        predictions = model_i_tanh.predict(feature_input)\n",
    "        pos = np.argmax(predictions)\n",
    "        Test_prediction.append(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "076b76ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.6607142857142857\n"
     ]
    }
   ],
   "source": [
    "test_acc = (Test_prediction == y_test).mean()\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c6d827",
   "metadata": {},
   "source": [
    "# Inception with Activation = softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9e5d49d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 108s 3s/step\n",
      "(2520, 5, 5, 2048)\n"
     ]
    }
   ],
   "source": [
    "inception_x_train_soft = inception_v3.preprocess_input(x_train.copy())\n",
    "inception_model_soft = inception_v3.InceptionV3(weights='imagenet', include_top=False)\n",
    "inception_features_soft = inception_model_soft.predict(inception_x_train_soft, batch_size=64, verbose=1)\n",
    "print(inception_features_soft.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f0d4faaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2048)\n",
      "(None, 7)\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape = (5, 5, 2048)) # to take 7 x 7 x 2048 images\n",
    "x = GlobalAveragePooling2D()(inputs) # to convert to 2048 feagures\n",
    "print(x.shape)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "x = Dense(500)(x) # add a dense layer, but not adding activation so that we can add batch-norm first\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"softmax\")(x)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "# Softmax layer to the output classes\n",
    "predictions = Dense(num_classes, activation='softmax')(x) # arg1 is: units = dimensionality of the output space.\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "70c87a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 5, 5, 2048)]      0         \n",
      "                                                                 \n",
      " global_average_pooling2d_8   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 500)               1024500   \n",
      "                                                                 \n",
      " batch_normalization_384 (Ba  (None, 500)              2000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_384 (Activation)  (None, 500)              0         \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 7)                 3507      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,030,007\n",
      "Trainable params: 1,029,007\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_i_soft = Model(inputs=inputs, outputs=predictions) # specify what is network input, and what is network output\n",
    "model_i_soft.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "da90500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_i_soft.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "56d71419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 1.9327 - accuracy: 0.4665 - val_loss: 1.9618 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 1.9125 - accuracy: 0.6313 - val_loss: 1.9836 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 1.8964 - accuracy: 0.6897 - val_loss: 2.0077 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 1.8799 - accuracy: 0.7312 - val_loss: 2.0306 - val_accuracy: 0.0000e+00\n",
      "Epoch 4: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2945c98e130>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',  patience=3, verbose=1)\n",
    "# stop if loss does not improve for 3 iterations\n",
    "\n",
    "model_i_soft.fit(inception_features_soft[:split_point], y_train[:split_point], batch_size=128, epochs=30, \n",
    "              validation_data=(inception_features_soft[split_point:], y_train[split_point:]), callbacks=[early_stop], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "057115aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_i_soft.save('model_i_soft.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "367b8e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_prediction = []\n",
    "for files in os.listdir('./Data/Test_2'):\n",
    "\n",
    "    if files== 'desktop.ini':\n",
    "        pass\n",
    "    else:    \n",
    "        test_img = get_image(f'./Data/Test_2/{files}')\n",
    "        image_batch = np.expand_dims(test_img, axis=0)\n",
    "        image_batch = np.copy(image_batch)\n",
    "        image_batch = inception_v3.preprocess_input(image_batch)\n",
    "        feature_input = inception_model_soft.predict(image_batch)\n",
    "        predictions = model_i_soft.predict(feature_input)\n",
    "        pos = np.argmax(predictions)\n",
    "        Test_prediction.append(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5869bef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.4857142857142857\n"
     ]
    }
   ],
   "source": [
    "test_acc = (Test_prediction == y_test).mean()\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cc6675",
   "metadata": {},
   "source": [
    "# Inception with Activation = elu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dcf7df9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 105s 3s/step\n",
      "(2520, 5, 5, 2048)\n"
     ]
    }
   ],
   "source": [
    "inception_x_train_elu = inception_v3.preprocess_input(x_train.copy())\n",
    "inception_model_elu = inception_v3.InceptionV3(weights='imagenet', include_top=False)\n",
    "inception_features_elu = inception_model_elu.predict(inception_x_train_elu, batch_size=64, verbose=1)\n",
    "print(inception_features_elu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aedfbc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2048)\n",
      "(None, 7)\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape = (5, 5, 2048)) # to take 7 x 7 x 2048 images\n",
    "x = GlobalAveragePooling2D()(inputs) # to convert to 2048 feagures\n",
    "print(x.shape)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "x = Dense(500)(x) # add a dense layer, but not adding activation so that we can add batch-norm first\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"elu\")(x)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "# Softmax layer to the output classes\n",
    "predictions = Dense(num_classes, activation='softmax')(x) # arg1 is: units = dimensionality of the output space.\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9d159467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 5, 5, 2048)]      0         \n",
      "                                                                 \n",
      " global_average_pooling2d_9   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 500)               1024500   \n",
      "                                                                 \n",
      " batch_normalization_479 (Ba  (None, 500)              2000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_479 (Activation)  (None, 500)              0         \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 7)                 3507      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,030,007\n",
      "Trainable params: 1,029,007\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_i_elu = Model(inputs=inputs, outputs=predictions) # specify what is network input, and what is network output\n",
    "model_i_elu.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e9240f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_i_elu.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c525d14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 1.3425 - accuracy: 0.5772 - val_loss: 0.2682 - val_accuracy: 0.9179\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.6230 - accuracy: 0.7835 - val_loss: 0.2078 - val_accuracy: 0.9214\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.5189 - accuracy: 0.8313 - val_loss: 0.0956 - val_accuracy: 0.9536\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.4300 - accuracy: 0.8509 - val_loss: 0.1491 - val_accuracy: 0.9393\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.4037 - accuracy: 0.8661 - val_loss: 0.0655 - val_accuracy: 0.9714\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.3750 - accuracy: 0.8638 - val_loss: 0.0416 - val_accuracy: 0.9964\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.3468 - accuracy: 0.8737 - val_loss: 0.0739 - val_accuracy: 0.9643\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.3639 - accuracy: 0.8679 - val_loss: 0.0549 - val_accuracy: 0.9857\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.3292 - accuracy: 0.8879 - val_loss: 0.1393 - val_accuracy: 0.9500\n",
      "Epoch 9: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2946605ce20>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',  patience=3, verbose=1)\n",
    "# stop if loss does not improve for 3 iterations\n",
    "\n",
    "model_i_elu.fit(inception_features_elu[:split_point], y_train[:split_point], batch_size=128, epochs=30, \n",
    "              validation_data=(inception_features_elu[split_point:], y_train[split_point:]), callbacks=[early_stop], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fa3de79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_i_elu.save('model_i_elu.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "65482cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_prediction = []\n",
    "for files in os.listdir('./Data/Test_2'):\n",
    "\n",
    "    if files== 'desktop.ini':\n",
    "        pass\n",
    "    else:    \n",
    "        test_img = get_image(f'./Data/Test_2/{files}')\n",
    "        image_batch = np.expand_dims(test_img, axis=0)\n",
    "        image_batch = np.copy(image_batch)\n",
    "        image_batch = inception_v3.preprocess_input(image_batch)\n",
    "        feature_input = inception_model_elu.predict(image_batch)\n",
    "        predictions = model_i_elu.predict(feature_input)\n",
    "        pos = np.argmax(predictions)\n",
    "        Test_prediction.append(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c50be140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.7642857142857142\n"
     ]
    }
   ],
   "source": [
    "test_acc = (Test_prediction == y_test).mean()\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10007ac2",
   "metadata": {},
   "source": [
    "# Inception with Activation = exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d07481c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 109s 3s/step\n",
      "(2520, 5, 5, 2048)\n"
     ]
    }
   ],
   "source": [
    "inception_x_train_ex = inception_v3.preprocess_input(x_train.copy())\n",
    "inception_model_ex = inception_v3.InceptionV3(weights='imagenet', include_top=False)\n",
    "inception_features_ex = inception_model_ex.predict(inception_x_train_ex, batch_size=64, verbose=1)\n",
    "print(inception_features_ex.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d78e9704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2048)\n",
      "(None, 7)\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape = (5, 5, 2048)) # to take 7 x 7 x 2048 images\n",
    "x = GlobalAveragePooling2D()(inputs) # to convert to 2048 feagures\n",
    "print(x.shape)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "x = Dense(500)(x) # add a dense layer, but not adding activation so that we can add batch-norm first\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"exponential\")(x)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "# Softmax layer to the output classes\n",
    "predictions = Dense(num_classes, activation='softmax')(x) # arg1 is: units = dimensionality of the output space.\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e18faddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_17 (InputLayer)       [(None, 5, 5, 2048)]      0         \n",
      "                                                                 \n",
      " global_average_pooling2d_10  (None, 2048)             0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 500)               1024500   \n",
      "                                                                 \n",
      " batch_normalization_574 (Ba  (None, 500)              2000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_574 (Activation)  (None, 500)              0         \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 7)                 3507      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,030,007\n",
      "Trainable params: 1,029,007\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_i_expo = Model(inputs=inputs, outputs=predictions) # specify what is network input, and what is network output\n",
    "model_i_expo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "99246a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_i_expo.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7dd0b8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 3.7565 - accuracy: 0.4612 - val_loss: 4.0204 - val_accuracy: 0.1893\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 1.8887 - accuracy: 0.6656 - val_loss: 0.9243 - val_accuracy: 0.8143\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 1.2839 - accuracy: 0.7259 - val_loss: 0.5954 - val_accuracy: 0.8607\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 1.1232 - accuracy: 0.7518 - val_loss: 0.5059 - val_accuracy: 0.8536\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 1s 27ms/step - loss: 0.9127 - accuracy: 0.7911 - val_loss: 0.1901 - val_accuracy: 0.9500\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.7887 - accuracy: 0.8112 - val_loss: 0.2365 - val_accuracy: 0.9571\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.7725 - accuracy: 0.7996 - val_loss: 0.2874 - val_accuracy: 0.9107\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.6893 - accuracy: 0.8277 - val_loss: 0.2120 - val_accuracy: 0.9250\n",
      "Epoch 8: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29473be8b50>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',  patience=3, verbose=1)\n",
    "# stop if loss does not improve for 3 iterations\n",
    "\n",
    "model_i_expo.fit(inception_features_ex[:split_point], y_train[:split_point], batch_size=128, epochs=30, \n",
    "              validation_data=(inception_features_ex[split_point:], y_train[split_point:]), callbacks=[early_stop], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2559b7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_i_expo.save('model_i_expo.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "355b32ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_prediction = []\n",
    "for files in os.listdir('./Data/Test_2'):\n",
    "\n",
    "    if files== 'desktop.ini':\n",
    "        pass\n",
    "    else:    \n",
    "        test_img = get_image(f'./Data/Test_2/{files}')\n",
    "        image_batch = np.expand_dims(test_img, axis=0)\n",
    "        image_batch = np.copy(image_batch)\n",
    "        image_batch = inception_v3.preprocess_input(image_batch)\n",
    "        feature_input = inception_model_ex.predict(image_batch)\n",
    "        predictions = model_i_expo.predict(feature_input)\n",
    "        pos = np.argmax(predictions)\n",
    "        Test_prediction.append(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "043c2a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.7214285714285714\n"
     ]
    }
   ],
   "source": [
    "test_acc = (Test_prediction == y_test).mean()\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58225607",
   "metadata": {},
   "source": [
    "# Inception with Optimizer = SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ed4f7071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 99s 2s/step\n",
      "(2520, 5, 5, 2048)\n"
     ]
    }
   ],
   "source": [
    "inception_x_train_sgd = inception_v3.preprocess_input(x_train.copy())\n",
    "inception_model_sgd = inception_v3.InceptionV3(weights='imagenet', include_top=False)\n",
    "inception_features_sgd = inception_model_sgd.predict(inception_x_train_sgd, batch_size=64, verbose=1)\n",
    "print(inception_features_sgd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ace7c25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2048)\n",
      "(None, 7)\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape = (5, 5, 2048)) # to take 7 x 7 x 2048 images\n",
    "x = GlobalAveragePooling2D()(inputs) # to convert to 2048 feagures\n",
    "print(x.shape)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "x = Dense(500)(x) # add a dense layer, but not adding activation so that we can add batch-norm first\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "# Softmax layer to the output classes\n",
    "predictions = Dense(num_classes, activation='softmax')(x) # arg1 is: units = dimensionality of the output space.\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5a4faa82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_19 (InputLayer)       [(None, 5, 5, 2048)]      0         \n",
      "                                                                 \n",
      " global_average_pooling2d_11  (None, 2048)             0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 500)               1024500   \n",
      "                                                                 \n",
      " batch_normalization_669 (Ba  (None, 500)              2000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_669 (Activation)  (None, 500)              0         \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 7)                 3507      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,030,007\n",
      "Trainable params: 1,029,007\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_i_sgd = Model(inputs=inputs, outputs=predictions) # specify what is network input, and what is network output\n",
    "model_i_sgd.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "47599c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_i_sgd.compile(loss='categorical_crossentropy', optimizer=\"sgd\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8fdd0366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 2.2732 - accuracy: 0.2116 - val_loss: 1.7501 - val_accuracy: 0.2250\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 1.7745 - accuracy: 0.3549 - val_loss: 1.7350 - val_accuracy: 0.2214\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 1.5624 - accuracy: 0.4317 - val_loss: 1.6240 - val_accuracy: 0.2786\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 1.4236 - accuracy: 0.4674 - val_loss: 1.4750 - val_accuracy: 0.4107\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 1.3542 - accuracy: 0.5071 - val_loss: 1.2865 - val_accuracy: 0.5464\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 1.2458 - accuracy: 0.5571 - val_loss: 1.1512 - val_accuracy: 0.6393\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 1.2326 - accuracy: 0.5522 - val_loss: 1.0502 - val_accuracy: 0.7214\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 1.1312 - accuracy: 0.5844 - val_loss: 0.9320 - val_accuracy: 0.7500\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 1.0761 - accuracy: 0.6228 - val_loss: 0.8480 - val_accuracy: 0.8107\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 1.0815 - accuracy: 0.6112 - val_loss: 0.8306 - val_accuracy: 0.7714\n",
      "Epoch 11/30\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 1.0063 - accuracy: 0.6429 - val_loss: 0.8058 - val_accuracy: 0.8000\n",
      "Epoch 12/30\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 1.0029 - accuracy: 0.6335 - val_loss: 0.7290 - val_accuracy: 0.8214\n",
      "Epoch 13/30\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.9331 - accuracy: 0.6585 - val_loss: 0.6894 - val_accuracy: 0.8464\n",
      "Epoch 14/30\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.9167 - accuracy: 0.6607 - val_loss: 0.7115 - val_accuracy: 0.8214\n",
      "Epoch 15/30\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.8967 - accuracy: 0.6893 - val_loss: 0.6793 - val_accuracy: 0.8500\n",
      "Epoch 16/30\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.8921 - accuracy: 0.6772 - val_loss: 0.6495 - val_accuracy: 0.8536\n",
      "Epoch 17/30\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.8677 - accuracy: 0.6893 - val_loss: 0.6270 - val_accuracy: 0.8607\n",
      "Epoch 18/30\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.8480 - accuracy: 0.7022 - val_loss: 0.5927 - val_accuracy: 0.8714\n",
      "Epoch 19/30\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.8439 - accuracy: 0.6973 - val_loss: 0.5749 - val_accuracy: 0.8750\n",
      "Epoch 20/30\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.8000 - accuracy: 0.7138 - val_loss: 0.5699 - val_accuracy: 0.8714\n",
      "Epoch 21/30\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.7850 - accuracy: 0.7237 - val_loss: 0.5675 - val_accuracy: 0.8750\n",
      "Epoch 22/30\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.8077 - accuracy: 0.7049 - val_loss: 0.5462 - val_accuracy: 0.8750\n",
      "Epoch 23/30\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.7671 - accuracy: 0.7263 - val_loss: 0.5391 - val_accuracy: 0.8750\n",
      "Epoch 24/30\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.7862 - accuracy: 0.7246 - val_loss: 0.5243 - val_accuracy: 0.8821\n",
      "Epoch 25/30\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.7793 - accuracy: 0.7263 - val_loss: 0.5103 - val_accuracy: 0.8893\n",
      "Epoch 26/30\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.7521 - accuracy: 0.7402 - val_loss: 0.4888 - val_accuracy: 0.8893\n",
      "Epoch 27/30\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.7309 - accuracy: 0.7388 - val_loss: 0.4713 - val_accuracy: 0.8929\n",
      "Epoch 28/30\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.7221 - accuracy: 0.7397 - val_loss: 0.4433 - val_accuracy: 0.9036\n",
      "Epoch 29/30\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.7282 - accuracy: 0.7429 - val_loss: 0.4230 - val_accuracy: 0.9036\n",
      "Epoch 30/30\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.7063 - accuracy: 0.7504 - val_loss: 0.4119 - val_accuracy: 0.9036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2947ee4e9a0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',  patience=3, verbose=1)\n",
    "# stop if loss does not improve for 3 iterations\n",
    "\n",
    "model_i_sgd.fit(inception_features_sgd[:split_point], y_train[:split_point], batch_size=128, epochs=30, \n",
    "              validation_data=(inception_features_sgd[split_point:], y_train[split_point:]), callbacks=[early_stop], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5796cb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_i_sgd.save('model_i_sgd.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "88648c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_prediction = []\n",
    "for files in os.listdir('./Data/Test_2'):\n",
    "\n",
    "    if files== 'desktop.ini':\n",
    "        pass\n",
    "    else:    \n",
    "        test_img = get_image(f'./Data/Test_2/{files}')\n",
    "        image_batch = np.expand_dims(test_img, axis=0)\n",
    "        image_batch = np.copy(image_batch)\n",
    "        image_batch = inception_v3.preprocess_input(image_batch)\n",
    "        feature_input = inception_model_sgd.predict(image_batch)\n",
    "        predictions = model_i_sgd.predict(feature_input)\n",
    "        pos = np.argmax(predictions)\n",
    "        Test_prediction.append(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "afbeab3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.7428571428571429\n"
     ]
    }
   ],
   "source": [
    "test_acc = (Test_prediction == y_test).mean()\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba2dadc",
   "metadata": {},
   "source": [
    "# Inception with Optimizer = RMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "16497a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 109s 3s/step\n",
      "(2520, 5, 5, 2048)\n"
     ]
    }
   ],
   "source": [
    "inception_x_train_rms = inception_v3.preprocess_input(x_train.copy())\n",
    "inception_model_rms = inception_v3.InceptionV3(weights='imagenet', include_top=False)\n",
    "inception_features_rms = inception_model_rms.predict(inception_x_train_rms, batch_size=64, verbose=1)\n",
    "print(inception_features_rms.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1cb12894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2048)\n",
      "(None, 7)\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape = (5, 5, 2048)) # to take 7 x 7 x 2048 images\n",
    "x = GlobalAveragePooling2D()(inputs) # to convert to 2048 feagures\n",
    "print(x.shape)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "x = Dense(500)(x) # add a dense layer, but not adding activation so that we can add batch-norm first\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "# Softmax layer to the output classes\n",
    "predictions = Dense(num_classes, activation='softmax')(x) # arg1 is: units = dimensionality of the output space.\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f2143a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_21 (InputLayer)       [(None, 5, 5, 2048)]      0         \n",
      "                                                                 \n",
      " global_average_pooling2d_12  (None, 2048)             0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 500)               1024500   \n",
      "                                                                 \n",
      " batch_normalization_764 (Ba  (None, 500)              2000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_764 (Activation)  (None, 500)              0         \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 7)                 3507      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,030,007\n",
      "Trainable params: 1,029,007\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_i_rms = Model(inputs=inputs, outputs=predictions) # specify what is network input, and what is network output\n",
    "model_i_rms.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4342394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_i_rms.compile(loss='categorical_crossentropy', optimizer=\"RMSprop\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0a6a9e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 2s 46ms/step - loss: 1.0969 - accuracy: 0.6192 - val_loss: 0.3038 - val_accuracy: 0.9321\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.6312 - accuracy: 0.7768 - val_loss: 0.2645 - val_accuracy: 0.9286\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.5242 - accuracy: 0.8214 - val_loss: 0.1817 - val_accuracy: 0.9464\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.4775 - accuracy: 0.8362 - val_loss: 0.1438 - val_accuracy: 0.9536\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.4178 - accuracy: 0.8589 - val_loss: 0.1567 - val_accuracy: 0.9357\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.3626 - accuracy: 0.8732 - val_loss: 0.0617 - val_accuracy: 0.9821\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.3646 - accuracy: 0.8732 - val_loss: 0.0723 - val_accuracy: 0.9714\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.2889 - accuracy: 0.8978 - val_loss: 0.0572 - val_accuracy: 0.9821\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 1s 49ms/step - loss: 0.2979 - accuracy: 0.8933 - val_loss: 0.1050 - val_accuracy: 0.9607\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.2620 - accuracy: 0.9103 - val_loss: 0.1114 - val_accuracy: 0.9607\n",
      "Epoch 11/30\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.2870 - accuracy: 0.9062 - val_loss: 0.0705 - val_accuracy: 0.9821\n",
      "Epoch 11: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29466aa11c0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',  patience=3, verbose=1)\n",
    "# stop if loss does not improve for 3 iterations\n",
    "\n",
    "model_i_rms.fit(inception_features_rms[:split_point], y_train[:split_point], batch_size=128, epochs=30, \n",
    "              validation_data=(inception_features_rms[split_point:], y_train[split_point:]), callbacks=[early_stop], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5b7a2d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_i_rms.save('model_i_rms.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "178acfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_prediction = []\n",
    "for files in os.listdir('./Data/Test_2'):\n",
    "\n",
    "    if files== 'desktop.ini':\n",
    "        pass\n",
    "    else:    \n",
    "        test_img = get_image(f'./Data/Test_2/{files}')\n",
    "        image_batch = np.expand_dims(test_img, axis=0)\n",
    "        image_batch = np.copy(image_batch)\n",
    "        image_batch = inception_v3.preprocess_input(image_batch)\n",
    "        feature_input = inception_model_rms.predict(image_batch)\n",
    "        predictions = model_i_rms.predict(feature_input)\n",
    "        pos = np.argmax(predictions)\n",
    "        Test_prediction.append(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6aa415ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.775\n"
     ]
    }
   ],
   "source": [
    "test_acc = (Test_prediction == y_test).mean()\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b01419",
   "metadata": {},
   "source": [
    "# Inception with Otpimizer = Adadlta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "aa78cb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 117s 3s/step\n",
      "(2520, 5, 5, 2048)\n"
     ]
    }
   ],
   "source": [
    "inception_x_train_ada = inception_v3.preprocess_input(x_train.copy())\n",
    "inception_model_ada = inception_v3.InceptionV3(weights='imagenet', include_top=False)\n",
    "inception_features_ada = inception_model_ada.predict(inception_x_train_ada, batch_size=64, verbose=1)\n",
    "print(inception_features_ada.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b716d4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2048)\n",
      "(None, 7)\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape = (5, 5, 2048)) # to take 7 x 7 x 2048 images\n",
    "x = GlobalAveragePooling2D()(inputs) # to convert to 2048 feagures\n",
    "print(x.shape)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "x = Dense(500)(x) # add a dense layer, but not adding activation so that we can add batch-norm first\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "# Softmax layer to the output classes\n",
    "predictions = Dense(num_classes, activation='softmax')(x) # arg1 is: units = dimensionality of the output space.\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c0cb0bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_23 (InputLayer)       [(None, 5, 5, 2048)]      0         \n",
      "                                                                 \n",
      " global_average_pooling2d_13  (None, 2048)             0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 500)               1024500   \n",
      "                                                                 \n",
      " batch_normalization_859 (Ba  (None, 500)              2000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_859 (Activation)  (None, 500)              0         \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 7)                 3507      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,030,007\n",
      "Trainable params: 1,029,007\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_i_ada = Model(inputs=inputs, outputs=predictions) # specify what is network input, and what is network output\n",
    "model_i_ada.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bd64e56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_i_ada.compile(loss='categorical_crossentropy', optimizer=\"Adadelta\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "90432890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 2s 42ms/step - loss: 2.7064 - accuracy: 0.1326 - val_loss: 2.2608 - val_accuracy: 0.0036\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 2.6408 - accuracy: 0.1353 - val_loss: 2.2451 - val_accuracy: 0.0036\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 2.6439 - accuracy: 0.1357 - val_loss: 2.2369 - val_accuracy: 0.0036\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 2.6344 - accuracy: 0.1357 - val_loss: 2.2279 - val_accuracy: 0.0036\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 2.5930 - accuracy: 0.1496 - val_loss: 2.2190 - val_accuracy: 0.0179\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 2.6186 - accuracy: 0.1446 - val_loss: 2.2123 - val_accuracy: 0.0179\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 2.5949 - accuracy: 0.1344 - val_loss: 2.2004 - val_accuracy: 0.0214\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 2.5802 - accuracy: 0.1375 - val_loss: 2.1910 - val_accuracy: 0.0536\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 2.5716 - accuracy: 0.1500 - val_loss: 2.1879 - val_accuracy: 0.0643\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 2.5783 - accuracy: 0.1446 - val_loss: 2.1849 - val_accuracy: 0.0643\n",
      "Epoch 11/30\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 2.5949 - accuracy: 0.1388 - val_loss: 2.1818 - val_accuracy: 0.0714\n",
      "Epoch 12/30\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 2.5270 - accuracy: 0.1554 - val_loss: 2.1851 - val_accuracy: 0.0714\n",
      "Epoch 13/30\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 2.5168 - accuracy: 0.1504 - val_loss: 2.1816 - val_accuracy: 0.0821\n",
      "Epoch 14/30\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 2.5404 - accuracy: 0.1397 - val_loss: 2.1789 - val_accuracy: 0.0714\n",
      "Epoch 15/30\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 2.4835 - accuracy: 0.1429 - val_loss: 2.1710 - val_accuracy: 0.0714\n",
      "Epoch 16/30\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 2.5008 - accuracy: 0.1496 - val_loss: 2.1669 - val_accuracy: 0.0714\n",
      "Epoch 17/30\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 2.4835 - accuracy: 0.1536 - val_loss: 2.1618 - val_accuracy: 0.0714\n",
      "Epoch 18/30\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 2.4983 - accuracy: 0.1607 - val_loss: 2.1580 - val_accuracy: 0.0714\n",
      "Epoch 19/30\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 2.4783 - accuracy: 0.1549 - val_loss: 2.1535 - val_accuracy: 0.0714\n",
      "Epoch 20/30\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 2.4566 - accuracy: 0.1638 - val_loss: 2.1499 - val_accuracy: 0.0714\n",
      "Epoch 21/30\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 2.4283 - accuracy: 0.1656 - val_loss: 2.1479 - val_accuracy: 0.0714\n",
      "Epoch 22/30\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 2.4196 - accuracy: 0.1705 - val_loss: 2.1437 - val_accuracy: 0.0714\n",
      "Epoch 23/30\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 2.4227 - accuracy: 0.1750 - val_loss: 2.1391 - val_accuracy: 0.0714\n",
      "Epoch 24/30\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 2.4290 - accuracy: 0.1545 - val_loss: 2.1336 - val_accuracy: 0.0714\n",
      "Epoch 25/30\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 2.4387 - accuracy: 0.1647 - val_loss: 2.1293 - val_accuracy: 0.0714\n",
      "Epoch 26/30\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 2.3835 - accuracy: 0.1719 - val_loss: 2.1222 - val_accuracy: 0.0714\n",
      "Epoch 27/30\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 2.3813 - accuracy: 0.1679 - val_loss: 2.1180 - val_accuracy: 0.0714\n",
      "Epoch 28/30\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 2.4268 - accuracy: 0.1723 - val_loss: 2.1231 - val_accuracy: 0.0714\n",
      "Epoch 29/30\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 2.4158 - accuracy: 0.1688 - val_loss: 2.1183 - val_accuracy: 0.0714\n",
      "Epoch 30/30\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 2.3857 - accuracy: 0.1746 - val_loss: 2.1163 - val_accuracy: 0.0714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x294904bae50>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',  patience=3, verbose=1)\n",
    "# stop if loss does not improve for 3 iterations\n",
    "\n",
    "model_i_ada.fit(inception_features_ada[:split_point], y_train[:split_point], batch_size=128, epochs=30, \n",
    "              validation_data=(inception_features_ada[split_point:], y_train[split_point:]), callbacks=[early_stop], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "13d35d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_i_ada.save('model_i_ada.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fbafdfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_prediction = []\n",
    "for files in os.listdir('./Data/Test_2'):\n",
    "\n",
    "    if files== 'desktop.ini':\n",
    "        pass\n",
    "    else:    \n",
    "        test_img = get_image(f'./Data/Test_2/{files}')\n",
    "        image_batch = np.expand_dims(test_img, axis=0)\n",
    "        image_batch = np.copy(image_batch)\n",
    "        image_batch = inception_v3.preprocess_input(image_batch)\n",
    "        feature_input = inception_model_ada.predict(image_batch)\n",
    "        predictions = model_i_ada.predict(feature_input)\n",
    "        pos = np.argmax(predictions)\n",
    "        Test_prediction.append(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b1e05c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.18928571428571428\n"
     ]
    }
   ],
   "source": [
    "test_acc = (Test_prediction == y_test).mean()\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979a1084",
   "metadata": {},
   "source": [
    "# Inception with Loss = MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "eded036b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 101s 2s/step\n",
      "(2520, 5, 5, 2048)\n"
     ]
    }
   ],
   "source": [
    "inception_x_train_mse = inception_v3.preprocess_input(x_train.copy())\n",
    "inception_model_mse = inception_v3.InceptionV3(weights='imagenet', include_top=False)\n",
    "inception_features_mse = inception_model_mse.predict(inception_x_train_mse, batch_size=64, verbose=1)\n",
    "print(inception_features_mse.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "01d230b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2048)\n",
      "(None, 7)\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape = (5, 5, 2048)) # to take 7 x 7 x 2048 images\n",
    "x = GlobalAveragePooling2D()(inputs) # to convert to 2048 feagures\n",
    "print(x.shape)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "x = Dense(500)(x) # add a dense layer, but not adding activation so that we can add batch-norm first\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "# Softmax layer to the output classes\n",
    "predictions = Dense(num_classes, activation='softmax')(x) # arg1 is: units = dimensionality of the output space.\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "662a5662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_25 (InputLayer)       [(None, 5, 5, 2048)]      0         \n",
      "                                                                 \n",
      " global_average_pooling2d_14  (None, 2048)             0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 500)               1024500   \n",
      "                                                                 \n",
      " batch_normalization_954 (Ba  (None, 500)              2000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_954 (Activation)  (None, 500)              0         \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 7)                 3507      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,030,007\n",
      "Trainable params: 1,029,007\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_i_mse = Model(inputs=inputs, outputs=predictions) # specify what is network input, and what is network output\n",
    "model_i_mse.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "dff2dd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_i_mse.compile(loss='mean_squared_error', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3642334a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0940 - accuracy: 0.4960 - val_loss: 0.0846 - val_accuracy: 0.6250\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.0518 - accuracy: 0.7464 - val_loss: 0.0262 - val_accuracy: 0.8571\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0434 - accuracy: 0.7817 - val_loss: 0.0192 - val_accuracy: 0.9000\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0342 - accuracy: 0.8317 - val_loss: 0.0283 - val_accuracy: 0.8643\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0312 - accuracy: 0.8536 - val_loss: 0.0216 - val_accuracy: 0.9000\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0305 - accuracy: 0.8545 - val_loss: 0.0142 - val_accuracy: 0.9250\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0273 - accuracy: 0.8665 - val_loss: 0.0100 - val_accuracy: 0.9571\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0272 - accuracy: 0.8701 - val_loss: 0.0086 - val_accuracy: 0.9464\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0252 - accuracy: 0.8862 - val_loss: 0.0071 - val_accuracy: 0.9500\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0237 - accuracy: 0.8893 - val_loss: 0.0103 - val_accuracy: 0.9500\n",
      "Epoch 11/30\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.0222 - accuracy: 0.9000 - val_loss: 0.0091 - val_accuracy: 0.9607\n",
      "Epoch 12/30\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0214 - accuracy: 0.8973 - val_loss: 0.0081 - val_accuracy: 0.9643\n",
      "Epoch 12: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2947faa3df0>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',  patience=3, verbose=1)\n",
    "# stop if loss does not improve for 3 iterations\n",
    "\n",
    "model_i_mse.fit(inception_features_mse[:split_point], y_train[:split_point], batch_size=128, epochs=30, \n",
    "              validation_data=(inception_features_mse[split_point:], y_train[split_point:]), callbacks=[early_stop], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2404f192",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_i_mse.save('model_i_mse.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "07ac9d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_prediction = []\n",
    "for files in os.listdir('./Data/Test_2'):\n",
    "\n",
    "    if files== 'desktop.ini':\n",
    "        pass\n",
    "    else:    \n",
    "        test_img = get_image(f'./Data/Test_2/{files}')\n",
    "        image_batch = np.expand_dims(test_img, axis=0)\n",
    "        image_batch = np.copy(image_batch)\n",
    "        image_batch = inception_v3.preprocess_input(image_batch)\n",
    "        feature_input = inception_model_mse.predict(image_batch)\n",
    "        predictions = model_i_mse.predict(feature_input)\n",
    "        pos = np.argmax(predictions)\n",
    "        Test_prediction.append(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0dbbc572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.7928571428571428\n"
     ]
    }
   ],
   "source": [
    "test_acc = (Test_prediction == y_test).mean()\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f09ff81",
   "metadata": {},
   "source": [
    "# Inception with Loss = MeanAbsoluteError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f7fe4652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 107s 3s/step\n",
      "(2520, 5, 5, 2048)\n"
     ]
    }
   ],
   "source": [
    "inception_x_train_mae = inception_v3.preprocess_input(x_train.copy())\n",
    "inception_model_mae = inception_v3.InceptionV3(weights='imagenet', include_top=False)\n",
    "inception_features_mae = inception_model_mae.predict(inception_x_train_mae, batch_size=64, verbose=1)\n",
    "print(inception_features_mae.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3c3bc7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2048)\n",
      "(None, 7)\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape = (5, 5, 2048)) # to take 7 x 7 x 2048 images\n",
    "x = GlobalAveragePooling2D()(inputs) # to convert to 2048 feagures\n",
    "print(x.shape)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "x = Dense(500)(x) # add a dense layer, but not adding activation so that we can add batch-norm first\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "# Softmax layer to the output classes\n",
    "predictions = Dense(num_classes, activation='softmax')(x) # arg1 is: units = dimensionality of the output space.\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c6e7d283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_29 (InputLayer)       [(None, 5, 5, 2048)]      0         \n",
      "                                                                 \n",
      " global_average_pooling2d_17  (None, 2048)             0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 500)               1024500   \n",
      "                                                                 \n",
      " batch_normalization_1051 (B  (None, 500)              2000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1051 (Activation  (None, 500)              0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 7)                 3507      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,030,007\n",
      "Trainable params: 1,029,007\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_i_mae = Model(inputs=inputs, outputs=predictions) # specify what is network input, and what is network output\n",
    "model_i_mae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "99c052ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_i_mae.compile(loss='mean_absolute_error', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "98c4063b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 0.1587 - accuracy: 0.4790 - val_loss: 0.2521 - val_accuracy: 0.0536\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0911 - accuracy: 0.7237 - val_loss: 0.2453 - val_accuracy: 0.0893\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0714 - accuracy: 0.7826 - val_loss: 0.1228 - val_accuracy: 0.6179\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0613 - accuracy: 0.8156 - val_loss: 0.0731 - val_accuracy: 0.8000\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0539 - accuracy: 0.8455 - val_loss: 0.0425 - val_accuracy: 0.8536\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.0481 - accuracy: 0.8562 - val_loss: 0.0367 - val_accuracy: 0.8964\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0444 - accuracy: 0.8714 - val_loss: 0.0333 - val_accuracy: 0.8964\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0428 - accuracy: 0.8723 - val_loss: 0.0209 - val_accuracy: 0.9393\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0393 - accuracy: 0.8839 - val_loss: 0.0165 - val_accuracy: 0.9393\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.0370 - accuracy: 0.8933 - val_loss: 0.0168 - val_accuracy: 0.9571\n",
      "Epoch 11/30\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0358 - accuracy: 0.8955 - val_loss: 0.0250 - val_accuracy: 0.9071\n",
      "Epoch 12/30\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0337 - accuracy: 0.9009 - val_loss: 0.0187 - val_accuracy: 0.9464\n",
      "Epoch 12: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29492007c70>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',  patience=3, verbose=1)\n",
    "# stop if loss does not improve for 3 iterations\n",
    "\n",
    "model_i_mae.fit(inception_features_mae[:split_point], y_train[:split_point], batch_size=128, epochs=30, \n",
    "              validation_data=(inception_features_mae[split_point:], y_train[split_point:]), callbacks=[early_stop], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0923841a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_i_mae.save('model_i_mae.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fd0373",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_prediction = []\n",
    "for files in os.listdir('./Data/Test_2'):\n",
    "\n",
    "    if files== 'desktop.ini':\n",
    "        pass\n",
    "    else:    \n",
    "        test_img = get_image(f'./Data/Test_2/{files}')\n",
    "        image_batch = np.expand_dims(test_img, axis=0)\n",
    "        image_batch = np.copy(image_batch)\n",
    "        image_batch = inception_v3.preprocess_input(image_batch)\n",
    "        feature_input = inception_model_mae.predict(image_batch)\n",
    "        predictions = model_i_mae.predict(feature_input)\n",
    "        pos = np.argmax(predictions)\n",
    "        Test_prediction.append(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "631c3bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.5392857142857143\n"
     ]
    }
   ],
   "source": [
    "test_acc = (Test_prediction == y_test).mean()\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ffba47",
   "metadata": {},
   "source": [
    "# Inception with Loss = Hinge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "155e287a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 110s 3s/step\n",
      "(2520, 5, 5, 2048)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import inception_v3\n",
    "inception_x_train_hinge = inception_v3.preprocess_input(x_train.copy())\n",
    "inception_model_hinge = inception_v3.InceptionV3(weights='imagenet', include_top=False)\n",
    "inception_features_hinge = inception_model_hinge.predict(inception_x_train_hinge, batch_size=64, verbose=1)\n",
    "print(inception_features_hinge.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e08195e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2048)\n",
      "(None, 7)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout, Activation, BatchNormalization\n",
    "\n",
    "inputs = Input(shape = (5, 5, 2048)) # to take 7 x 7 x 2048 images\n",
    "x = GlobalAveragePooling2D()(inputs) # to convert to 2048 feagures\n",
    "print(x.shape)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "x = Dense(500)(x) # add a dense layer, but not adding activation so that we can add batch-norm first\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "# Softmax layer to the output classes\n",
    "predictions = Dense(num_classes, activation='softmax')(x) # arg1 is: units = dimensionality of the output space.\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bc5b72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 5, 5, 2048)]      0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 500)               1024500   \n",
      "                                                                 \n",
      " batch_normalization_94 (Bat  (None, 500)              2000      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_94 (Activation)  (None, 500)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 3507      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,030,007\n",
      "Trainable params: 1,029,007\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "model_i_h = Model(inputs=inputs, outputs=predictions) # specify what is network input, and what is network output\n",
    "model_i_h.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18e8513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_i_h.compile(loss='hinge', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93510011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 2s 39ms/step - loss: 1.0087 - accuracy: 0.5116 - val_loss: 1.1391 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.9504 - accuracy: 0.7058 - val_loss: 1.1352 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.9310 - accuracy: 0.7696 - val_loss: 1.1060 - val_accuracy: 0.1143\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.9199 - accuracy: 0.8112 - val_loss: 0.9598 - val_accuracy: 0.7036\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.9138 - accuracy: 0.8321 - val_loss: 0.9238 - val_accuracy: 0.8036\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.9064 - accuracy: 0.8576 - val_loss: 0.9001 - val_accuracy: 0.8857\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.9042 - accuracy: 0.8625 - val_loss: 0.8960 - val_accuracy: 0.8857\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.9006 - accuracy: 0.8705 - val_loss: 0.8884 - val_accuracy: 0.9107\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.8967 - accuracy: 0.8830 - val_loss: 0.8780 - val_accuracy: 0.9357\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.8967 - accuracy: 0.8821 - val_loss: 0.8794 - val_accuracy: 0.9286\n",
      "Epoch 11/30\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.8933 - accuracy: 0.8924 - val_loss: 0.8804 - val_accuracy: 0.9286\n",
      "Epoch 12/30\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.8920 - accuracy: 0.8964 - val_loss: 0.8749 - val_accuracy: 0.9464\n",
      "Epoch 13/30\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.8907 - accuracy: 0.9071 - val_loss: 0.8715 - val_accuracy: 0.9571\n",
      "Epoch 14/30\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.8874 - accuracy: 0.9143 - val_loss: 0.8708 - val_accuracy: 0.9571\n",
      "Epoch 15/30\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.8877 - accuracy: 0.9103 - val_loss: 0.8735 - val_accuracy: 0.9571\n",
      "Epoch 16/30\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.8874 - accuracy: 0.9156 - val_loss: 0.8753 - val_accuracy: 0.9571\n",
      "Epoch 17/30\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.8859 - accuracy: 0.9219 - val_loss: 0.8715 - val_accuracy: 0.9571\n",
      "Epoch 17: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f7000a53d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss',  patience=3, verbose=1)\n",
    "# stop if loss does not improve for 3 iterations\n",
    "\n",
    "model_i_h.fit(inception_features_hinge[:split_point], y_train[:split_point], batch_size=128, epochs=30, \n",
    "              validation_data=(inception_features_hinge[split_point:], y_train[split_point:]), callbacks=[early_stop], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62120f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_i_h.save('model_i_h.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98890e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_prediction = []\n",
    "for files in os.listdir('./Data/Test_2'):\n",
    "\n",
    "    if files== 'desktop.ini':\n",
    "        pass\n",
    "    else:    \n",
    "        test_img = get_image(f'./Data/Test_2/{files}')\n",
    "        image_batch = np.expand_dims(test_img, axis=0)\n",
    "        image_batch = np.copy(image_batch)\n",
    "        image_batch = inception_v3.preprocess_input(image_batch)\n",
    "        feature_input = inception_model_hinge.predict(image_batch)\n",
    "        predictions = model_i_h.predict(feature_input)\n",
    "        pos = np.argmax(predictions)\n",
    "        Test_prediction.append(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28488b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.7892857142857143\n"
     ]
    }
   ],
   "source": [
    "y_test = pd.read_excel(r'./Data/test_2_label.xlsx',usecols=[1,1])\n",
    "y_test = y_test.to_numpy()\n",
    "y_test = np.squeeze(y_test)\n",
    "test_acc = (Test_prediction == y_test).mean()\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89733b56",
   "metadata": {},
   "source": [
    "# Inception with Loss = SquaredHinge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d19531c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 102s 3s/step\n",
      "(2520, 5, 5, 2048)\n"
     ]
    }
   ],
   "source": [
    "inception_x_train_sh = inception_v3.preprocess_input(x_train.copy())\n",
    "inception_model_sh = inception_v3.InceptionV3(weights='imagenet', include_top=False)\n",
    "inception_features_sh = inception_model_sh.predict(inception_x_train_sh, batch_size=64, verbose=1)\n",
    "print(inception_features_sh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2946f786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2048)\n",
      "(None, 7)\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape = (5, 5, 2048)) # to take 7 x 7 x 2048 images\n",
    "x = GlobalAveragePooling2D()(inputs) # to convert to 2048 feagures\n",
    "print(x.shape)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "x = Dense(500)(x) # add a dense layer, but not adding activation so that we can add batch-norm first\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "# Softmax layer to the output classes\n",
    "predictions = Dense(num_classes, activation='softmax')(x) # arg1 is: units = dimensionality of the output space.\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "900fa976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 5, 5, 2048)]      0         \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 500)               1024500   \n",
      "                                                                 \n",
      " batch_normalization_189 (Ba  (None, 500)              2000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_189 (Activation)  (None, 500)              0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 7)                 3507      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,030,007\n",
      "Trainable params: 1,029,007\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_i_sh = Model(inputs=inputs, outputs=predictions) # specify what is network input, and what is network output\n",
    "model_i_sh.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07b2961a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_i_sh.compile(loss='squared_hinge', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e45a7741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 1.1019 - accuracy: 0.5268 - val_loss: 1.1163 - val_accuracy: 0.5286\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.9966 - accuracy: 0.7504 - val_loss: 0.9947 - val_accuracy: 0.7821\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.9691 - accuracy: 0.8054 - val_loss: 0.9296 - val_accuracy: 0.8786\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.9526 - accuracy: 0.8388 - val_loss: 0.9047 - val_accuracy: 0.9286\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.9390 - accuracy: 0.8594 - val_loss: 0.9013 - val_accuracy: 0.9250\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.9367 - accuracy: 0.8665 - val_loss: 0.8933 - val_accuracy: 0.9357\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.9284 - accuracy: 0.8826 - val_loss: 0.8929 - val_accuracy: 0.9357\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.9275 - accuracy: 0.8813 - val_loss: 0.8907 - val_accuracy: 0.9393\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.9199 - accuracy: 0.8969 - val_loss: 0.8914 - val_accuracy: 0.9393\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.9226 - accuracy: 0.8884 - val_loss: 0.8840 - val_accuracy: 0.9536\n",
      "Epoch 11/30\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.9151 - accuracy: 0.9054 - val_loss: 0.8828 - val_accuracy: 0.9643\n",
      "Epoch 12/30\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.9148 - accuracy: 0.9036 - val_loss: 0.8868 - val_accuracy: 0.9429\n",
      "Epoch 13/30\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.9125 - accuracy: 0.9089 - val_loss: 0.8840 - val_accuracy: 0.9429\n",
      "Epoch 14/30\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.9075 - accuracy: 0.9152 - val_loss: 0.8825 - val_accuracy: 0.9429\n",
      "Epoch 15/30\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.9099 - accuracy: 0.9112 - val_loss: 0.8939 - val_accuracy: 0.9429\n",
      "Epoch 16/30\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.9072 - accuracy: 0.9165 - val_loss: 0.8969 - val_accuracy: 0.9286\n",
      "Epoch 17/30\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.9042 - accuracy: 0.9241 - val_loss: 0.8954 - val_accuracy: 0.9286\n",
      "Epoch 17: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f703d74430>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',  patience=3, verbose=1)\n",
    "# stop if loss does not improve for 3 iterations\n",
    "\n",
    "model_i_sh.fit(inception_features_sh[:split_point], y_train[:split_point], batch_size=128, epochs=30, \n",
    "              validation_data=(inception_features_sh[split_point:], y_train[split_point:]), callbacks=[early_stop], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0abb99f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_i_sh.save('model_i_sh.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a75e5ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_prediction = []\n",
    "for files in os.listdir('./Data/Test_2'):\n",
    "\n",
    "    if files== 'desktop.ini':\n",
    "        pass\n",
    "    else:    \n",
    "        test_img = get_image(f'./Data/Test_2/{files}')\n",
    "        image_batch = np.expand_dims(test_img, axis=0)\n",
    "        image_batch = np.copy(image_batch)\n",
    "        image_batch = inception_v3.preprocess_input(image_batch)\n",
    "        feature_input = inception_model_sh.predict(image_batch)\n",
    "        predictions = model_i_sh.predict(feature_input)\n",
    "        pos = np.argmax(predictions)\n",
    "        Test_prediction.append(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a974ca09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.7857142857142857\n"
     ]
    }
   ],
   "source": [
    "test_acc = (Test_prediction == y_test).mean()\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14316117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d9ad24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ea4a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
