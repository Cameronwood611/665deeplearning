{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b598b15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.applications import resnet50\n",
    "from keras_applications import resnext\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddcdfd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_train_images: 2520\n",
      "Types: Index(['distribute', 'ineq', 'integral', 'limit', 'matrix', 'series', 'sqrt'], dtype='object')\n",
      "num_classes: 7\n"
     ]
    }
   ],
   "source": [
    "labels = pd.read_csv('Data/train_label.csv')\n",
    "labels['Type'].value_counts()\n",
    "sample = pd.read_csv('Data/sample_submission.csv')\n",
    "num_train_images = 2520  # we choose 3300 images for this assignment. It works for a machine having 8Gb Ram. You can adjust it if your Ram is different. \n",
    "split_point = 2240 # split the data into training data [0:3000] and val data [3000:]\n",
    "print('num_train_images:', num_train_images)\n",
    "types = sample.columns[1:]\n",
    "print('Types:', types)\n",
    "num_classes = len(types)\n",
    "print('num_classes:', num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb5b3caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "\n",
    "img_width = 224\n",
    "\n",
    "def get_image(filename):\n",
    "    ########################################################################\n",
    "    # TODO: Your code here...\n",
    "    ########################################################################\n",
    "    original = load_img(filename, target_size=(224,224))\n",
    "    numpy_image = img_to_array(original)\n",
    "    image_batch = np.expand_dims(numpy_image, axis=0)\n",
    "    return image_batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "561cb5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 images loaded\n",
      "2000 images loaded\n"
     ]
    }
   ],
   "source": [
    "x_train = np.zeros((num_train_images, img_width, img_width, 3), dtype=np.uint8)\n",
    "y_train = np.zeros((num_train_images, num_classes), dtype=np.uint8)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for i in range(num_train_images):\n",
    "    x_train[i] = get_image('Data/train/%s.png' % labels['id'][i])\n",
    "    pos_arrays = (types == labels['Type'][i]).nonzero() # recall that types is the array of classes\n",
    "    pos = pos_arrays[0][0]\n",
    "    y_train[i][pos] = 1\n",
    "    count += 1\n",
    "    if(count % 1000 == 0): print(count, 'images loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eedbf45",
   "metadata": {},
   "source": [
    "### Xception with nothing changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc9d949f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 187s 5s/step\n",
      "(2520, 7, 7, 2048)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import xception\n",
    "xception_x_train = xception.preprocess_input(x_train.copy())\n",
    "xception_model = xception.Xception(weights='imagenet', include_top=False)\n",
    "xception_features = xception_model.predict(xception_x_train, batch_size=64, verbose=1)\n",
    "print(xception_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "835c4687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2048)\n",
      "(None, 7)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout, Activation, BatchNormalization\n",
    "\n",
    "inputs = Input(shape = (7, 7, 2048)) # to take 7 x 7 x 2048 images\n",
    "x = GlobalAveragePooling2D()(inputs) # to convert to 2048 feagures\n",
    "print(x.shape)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "x = Dense(500)(x) # add a dense layer, but not adding activation so that we can add batch-norm first\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Dropout(0.5)(x) # add a dropout layer\n",
    "# Softmax layer to the output classes\n",
    "predictions = Dense(num_classes, activation='softmax')(x) # arg1 is: units = dimensionality of the output space.\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40d40014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 7, 7, 2048)]      0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 500)               1024500   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 500)              2000      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation (Activation)     (None, 500)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 3507      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,030,007\n",
      "Trainable params: 1,029,007\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "model_x = Model(inputs=inputs, outputs=predictions) # specify what is network input, and what is network output\n",
    "model_x.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4cece05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_x.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0894dc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 6s 52ms/step - loss: 1.4119 - accuracy: 0.5353 - val_loss: 1.9369 - val_accuracy: 0.0393\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 0.8633 - accuracy: 0.6893 - val_loss: 1.2222 - val_accuracy: 0.6857\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.7101 - accuracy: 0.7478 - val_loss: 0.9915 - val_accuracy: 0.8214\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.6323 - accuracy: 0.7759 - val_loss: 1.0236 - val_accuracy: 0.7107\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.5736 - accuracy: 0.8054 - val_loss: 0.8390 - val_accuracy: 0.7821\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.5225 - accuracy: 0.8152 - val_loss: 0.8310 - val_accuracy: 0.7393\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.5064 - accuracy: 0.8254 - val_loss: 0.7009 - val_accuracy: 0.8179\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.4753 - accuracy: 0.8344 - val_loss: 0.6460 - val_accuracy: 0.8536\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.4547 - accuracy: 0.8339 - val_loss: 0.5558 - val_accuracy: 0.8786\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 1s 49ms/step - loss: 0.4204 - accuracy: 0.8598 - val_loss: 0.6208 - val_accuracy: 0.7893\n",
      "Epoch 11/30\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.4045 - accuracy: 0.8598 - val_loss: 0.5619 - val_accuracy: 0.8714\n",
      "Epoch 12/30\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.3875 - accuracy: 0.8696 - val_loss: 0.3993 - val_accuracy: 0.9321\n",
      "Epoch 13/30\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.3585 - accuracy: 0.8768 - val_loss: 0.3520 - val_accuracy: 0.9393\n",
      "Epoch 14/30\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.3638 - accuracy: 0.8754 - val_loss: 0.3284 - val_accuracy: 0.9429\n",
      "Epoch 15/30\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.3377 - accuracy: 0.8866 - val_loss: 0.3316 - val_accuracy: 0.9607\n",
      "Epoch 16/30\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.3247 - accuracy: 0.8821 - val_loss: 0.3978 - val_accuracy: 0.8679\n",
      "Epoch 17/30\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.3432 - accuracy: 0.8804 - val_loss: 0.3876 - val_accuracy: 0.8750\n",
      "Epoch 17: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23cb5763b50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss',  patience=3, verbose=1)\n",
    "# stop if loss does not improve for 3 iterations\n",
    "\n",
    "model_x.fit(xception_features[:split_point], y_train[:split_point], batch_size=128, epochs=30, \n",
    "              validation_data=(xception_features[split_point:], y_train[split_point:]), callbacks=[early_stop], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ef692a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_x.save('model_x.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "508e3e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_prediction = []\n",
    "for files in os.listdir('./Data/Test_2'):\n",
    "\n",
    "    if files== 'desktop.ini':\n",
    "        pass\n",
    "    else:    \n",
    "        test_img = get_image(f'./Data/Test_2/{files}')\n",
    "        image_batch = np.expand_dims(test_img, axis=0)\n",
    "        image_batch = np.copy(image_batch)\n",
    "        image_batch = xception.preprocess_input(image_batch)\n",
    "        feature_input = xception_model.predict(image_batch)\n",
    "        predictions = model_x.predict(feature_input)\n",
    "        pos = np.argmax(predictions)\n",
    "        Test_prediction.append(pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e96ea036",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.read_excel(r'./Data/test_2_label.xlsx',usecols=[1,1])\n",
    "y_test = y_test.to_numpy()\n",
    "y_test = np.squeeze(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1c66a230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.2857142857142857\n"
     ]
    }
   ],
   "source": [
    "test_acc = (Test_prediction == y_test).mean()\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d212ccf",
   "metadata": {},
   "source": [
    "# Xception with Activation = Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d08ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
